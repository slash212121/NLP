{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT-for-Sentiment-Analysis_PromisedNeverland.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7da066509e548a4b2b756eeb5536759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ddc1ea05a5b4e028312519ed54db10a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_62fbd8a16f9f4e52b06f95f36fc89419",
              "IPY_MODEL_b38b73520a8f4731a498bfaa505e7281"
            ]
          }
        },
        "6ddc1ea05a5b4e028312519ed54db10a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "62fbd8a16f9f4e52b06f95f36fc89419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d0e48e5c7cd84d629ed330d78519426c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_801703a7905a489aa58a7ac644630c57"
          }
        },
        "b38b73520a8f4731a498bfaa505e7281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6401d37d85d942018cb14436fc202630",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.05MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1df0e23b6dc641c8b3d7ceeefa048171"
          }
        },
        "d0e48e5c7cd84d629ed330d78519426c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "801703a7905a489aa58a7ac644630c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6401d37d85d942018cb14436fc202630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1df0e23b6dc641c8b3d7ceeefa048171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "28500815f96941b4917ced65cd1f511a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0efd5cebf34f4d368de81de442e3b311",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7748a048c86484f898874fdd9f7f0e5",
              "IPY_MODEL_f17b56ffc74443b583e5768b214a79e1"
            ]
          }
        },
        "0efd5cebf34f4d368de81de442e3b311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7748a048c86484f898874fdd9f7f0e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6f7d85d1b7949fa808373f40d3c3b76",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ea3ef6b3390489e92e071e872c0a25f"
          }
        },
        "f17b56ffc74443b583e5768b214a79e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bc69720a39949378f1ef66fab9ad676",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:37&lt;00:00, 11.5B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6f6eba277c74a15a392bfb499270053"
          }
        },
        "c6f7d85d1b7949fa808373f40d3c3b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ea3ef6b3390489e92e071e872c0a25f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7bc69720a39949378f1ef66fab9ad676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6f6eba277c74a15a392bfb499270053": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "703607fec0a144488f84b63e2ae16778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d621caccd3c44d1a7c17d1709278420",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d09a75d89fc441249dd9992c871e526c",
              "IPY_MODEL_ac734e662cd94bf5a69259b6d1fa2887"
            ]
          }
        },
        "0d621caccd3c44d1a7c17d1709278420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d09a75d89fc441249dd9992c871e526c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_56e0180c76e94d1087a6e27e3ef5cb66",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d032092c2f84d80b4e02640e134c79b"
          }
        },
        "ac734e662cd94bf5a69259b6d1fa2887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9cb97864edf041cead3a00c102eaffa3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:12&lt;00:00, 35.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8de5ffe56e854fccb2530bac4e3ec468"
          }
        },
        "56e0180c76e94d1087a6e27e3ef5cb66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d032092c2f84d80b4e02640e134c79b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cb97864edf041cead3a00c102eaffa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8de5ffe56e854fccb2530bac4e3ec468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqg4y371CM7X"
      },
      "source": [
        "# Fine-tuning BERT for Sentiment Analysis On My Anime List Reviews\n",
        "[![Portfolio](https://img.shields.io/badge/Portfolio-chriskhanhtran.github.io-blue?logo=GitHub)](https://chriskhanhtran.github.io/) 코드 참조 및 개조"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2D_810Uruqe"
      },
      "source": [
        "# A - Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT93d88Pcepn"
      },
      "source": [
        "해당 프로젝트는 MAL(My Anime List)이라는 애니메이션 평점 사이트 댓글들을 활용하여 BERT모델을 Fine Tuning한 프로젝트이다. 크롤링의 간편성과 레이블링을 하는 시간을 절약하기 위해서 압도적으로 부정적인 평들이 많은 \"약속의 네버랜드 시즌2(The Promised Neverland Season 2, 이후 네버랜드)\"과 압도적으로 긍정적인 평들이 많은 \"강철의 연금술사:브라더후드(Full Metal Alchemist: Brotherhood, 이후 강연)\"을 활용하기로 했다.\n",
        "\n",
        "강연의 댓글들을 읽다보면 거의 모든 것들이 긍정의 표시이기 때문에 모든 sentiment의 label을 긍정인 1로 하였고, 네버랜드는 안타깝게도 거의 모든 댓글이 완전 부정이거나 약한 부정을 하고 있는 것으로 보아 모든 sentiment의 label을 0으로 조정하였다. \n",
        "\n",
        "데이터는 MAL에서 댓글을 크롤링하였고, csv파일로 정리하였다. \n",
        "\n",
        "HuggingFace의 transformers 라이버러리를 활용하여 사전학습된 BERT모델을 FIne Tuning하였고 일반적인 TF-IDF Vectorizer와 Naive Bayes 분류 알고리즘과 성능을 비교하였다.\n",
        "\n",
        "\n",
        "**Reference**:\n",
        "\n",
        "To understand **Transformer** (the architecture which BERT is built on) and learn how to implement BERT, I highly recommend reading the following sources:\n",
        "\n",
        "- [The Illustrated BERT, ELMo, and co.](http://jalammar.github.io/illustrated-bert/): A very clear and well-written guide to understand BERT.\n",
        "- [The documentation of the `transformers` library](https://huggingface.co/transformers/v2.2.0/index.html)\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](http://mccormickml.com/2019/07/22/BERT-fine-tuning/) by [Chris McCormick](http://mccormickml.com/): A very detailed tutorial showing how to use BERT with the HuggingFace PyTorch library.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slO_rmYgwmmE"
      },
      "source": [
        "# B - Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31OW0dhozvli"
      },
      "source": [
        "## 1. Load Essential Libraries(필수적인 라이브러리를 가져온다)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lTXsMK3sNYr"
      },
      "source": [
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u07WRKnxsX96"
      },
      "source": [
        "## 2. Dataset(데이터셋을 준비해온다)\n",
        "### 원래 프로젝트에서는 Airline complaint 데이터셋을 이용하여 튜닝하였으나, 이번 프로젝트는 자체적으로 크롤링해온 데이터를 활용하고자 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVkXcFzrtREn"
      },
      "source": [
        "### 2.2. Load Train Data\n",
        "Fine tuning에 학습될 데이터셋은 두개가 있다. 하나는 모두 긍정으로 표기되어 있는 강연데이터셋과 다른 하나는 모두 부정으로 표기되어 있는 네버렌드 데이터셋이다. \n",
        "\n",
        "review의 칼럼을 활용하여 학습을 할것이고, 긍정인지 부정인지의 여부(즉 종속변수)는 sentiment칼럼을 활용할 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqpTBHkDJFBz",
        "outputId": "af4d5df0-004e-41be-8086-eb56a7e30214"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwjmiM2ktA7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b77bdb-afbf-4422-9746-e40849d804e4"
      },
      "source": [
        " # Load data and set labels\n",
        "data_review = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/promised_neverland.csv')\n",
        "\n",
        "# Display 5 random samples\n",
        "data_review = data_review.rename(columns={'Unnamed: 0': 'review_id'})\n",
        "data_review['sentiment'] = 0\n",
        "len(data_review)\n",
        "## 약속의 네버랜드 댓글 수는 총 274개이다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhJnIR21aNc3",
        "outputId": "2b038e0c-cc90-46ef-e8e6-a9e57afed873"
      },
      "source": [
        "data_review2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/fma.csv')\n",
        "\n",
        "# Display 5 random samples\n",
        "data_review2 = data_review2.rename(columns={'Unnamed: 0': 'review_id'})\n",
        "data_review2['sentiment'] = 1\n",
        "len(data_review2)\n",
        "## 강철의 연금술사의 댓글 수는 380개이다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "hHkYQxsAasjn",
        "outputId": "887f0f88-04c6-4797-f680-1aeafdba150c"
      },
      "source": [
        "data = pd.concat([data_review, data_review2], axis=0).reset_index(drop=True)\n",
        "data.sample(5)\n",
        "## 두 데이터셋을 합침"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>Rushed story and...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>120</td>\n",
              "      <td>This series is o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>81</td>\n",
              "      <td>I couldnt wait f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>120</td>\n",
              "      <td>Welp Where do I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>333</td>\n",
              "      <td>Overrated Just a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     review_id                                             review  sentiment\n",
              "43          43                                Rushed story and...          0\n",
              "394        120                                This series is o...          1\n",
              "81          81                                I couldnt wait f...          0\n",
              "120        120                                Welp Where do I ...          0\n",
              "607        333                                Overrated Just a...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cp-vfxKZvl6M"
      },
      "source": [
        "합쳐진 데이터셋을 학습데이터와 성능을 평가 할 수 있는 데이터셋으로 9:1 비율로 나눈다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4HKAFTbvMwI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = data.review.values\n",
        "y = data.sentiment.values\n",
        "\n",
        "X_train, X_test, y_train, y_test =\\\n",
        "    train_test_split(X, y, test_size=0.1, random_state=2020)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pErITNxtyNpe"
      },
      "source": [
        "### 2.3. Load Test Data\n",
        "test data를 준비한다. \"무직전생(Mushoku Tensei)\" 리뷰들이 부정적인 리뷰와 긍정적인 리뷰들이 적절히 섞여있어 선정하게 됨. 학습된 모델을 바탕으로 다음 데이터셋에 나와있는 리뷰들의 감성분석을 시행할 것이다. test data의 크기는 352개이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JWXnfBlwyWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a396c1e-4664-4ddd-fa23-d64c3435b59b"
      },
      "source": [
        "# Load test data\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/mushoku.csv')\n",
        "test_data = test_data.rename(columns={'Unnamed: 0': 'review_id'})\n",
        "# Keep important columns\n",
        "test_data = test_data[['review_id', 'review']]\n",
        "\n",
        "# Display 5 samples from the test data\n",
        "test_data.sample(5)\n",
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X79dYY3sxDCi"
      },
      "source": [
        "## 3. Set up GPU for training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi1CoEOL1puh"
      },
      "source": [
        "구글 콜랩이 제공하는 GPU를 활용하여 학습할 것이다. 파이토치를 활용하여 GPU의 존재여부를 확인한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7hxtI4l0SUJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc5dd2d-44b2-4a37-c02c-1f3061366ebf"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j6EbXLs12Kz"
      },
      "source": [
        "# C - Baseline: TF-IDF + Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eWj6qFpA3TE"
      },
      "source": [
        "In this baseline approach, first we will use TF-IDF to vectorize our text data. Then we will use the Naive Bayes model as our classifier. BERT모델을 적용하기 전에, 기본적인 TF-IDF벡터화를 통해(카운트 기반의 BOW을 활용한다), 그 후 기본적인 Naive Bayes모델을 활용하여 분류를 해본다. 이는 BERT모델의 성능차이를 보기 위한 비교모델이다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeljUmsqAUpt"
      },
      "source": [
        "## 1. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU754-QPAwBt"
      },
      "source": [
        "### 1.1. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_OzXFcfCBOa"
      },
      "source": [
        "BOW기법으로 벡터화를 진행할 경우, 단어의 출현 빈도에 따라 벡터화하기 때문에, 문서의 의미에 기여하지 않는 불용어(a, the와 같은 관사)들은 제거해두는 것이 좋다. 이를 위해 nltk 패키지 내재되어있는 불용어 사전을 활용할 것이다. 또한, 특수 기호들 및 띄어쓰기를 제거하도록 할 것이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98rwWTSw_dEI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc665ee-9619-4726-bc91-11f0f2f487f1"
      },
      "source": [
        "import nltk\n",
        "# Uncomment to download \"stopwords\"\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def text_preprocessing(s):\n",
        "    \"\"\"\n",
        "    - Lowercase the sentence\n",
        "    - Change \"'t\" to \"not\"\n",
        "    - Remove \"@name\"\n",
        "    - Isolate and remove punctuations except \"?\"\n",
        "    - Remove other special characters\n",
        "    - Remove stop words except \"not\" and \"can\"\n",
        "    - Remove trailing whitespace\n",
        "    \"\"\"\n",
        "    s = s.lower()\n",
        "    # Change 't to 'not'\n",
        "    s = re.sub(r\"\\'t\", \" not\", s)\n",
        "    # Remove @name\n",
        "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
        "    # Isolate and remove punctuations except '?'\n",
        "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
        "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
        "    # Remove some special characters\n",
        "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
        "    # Remove stopwords except 'not' and 'can'\n",
        "    s = \" \".join([word for word in s.split()\n",
        "                  if word not in stopwords.words('english')\n",
        "                  or word in ['not', 'can']])\n",
        "    # Remove trailing whitespace\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    \n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8jpfxygCvww"
      },
      "source": [
        "### 1.2. TF-IDF Vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbD689AMC-aB"
      },
      "source": [
        "TF-IDF벡터화 기법은 한 문서에서 사용되는 단어가 다른 문서에 비해서 상대적인 중요도를 비교한 것을 바탕으로 벡터화하는 카운트기반의 벡터화기법이다. Naive Bayes모델에 데이터를 학습시키기 전, TF-IDF방법으로 벡터화를 하는 과정을 거친다. scikitlearn의 TFidfVectorizer를 활용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOQ3X7hPDYhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9bb4fb-5f67-4fbc-c0ca-68487d59908f"
      },
      "source": [
        "%%time\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Preprocess text\n",
        "X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train])\n",
        "X_test_preprocessed = np.array([text_preprocessing(text) for text in X_test])\n",
        "\n",
        "# Calculate TF-IDF\n",
        "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
        "                         binary=True,\n",
        "                         smooth_idf=False)\n",
        "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
        "X_test_tfidf = tf_idf.transform(X_test_preprocessed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 27.7 s, sys: 3.14 s, total: 30.8 s\n",
            "Wall time: 30.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arsEHOKzFxdv"
      },
      "source": [
        "## 2. Train Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63HQtpzOInq-"
      },
      "source": [
        "### 2.1. Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z5E0Fa6GUyd"
      },
      "source": [
        "Cross validation(교차검증) 및 AUC Score(클수록 정확도가 높다)를 평가 수치로 하여 이를 극대화 할 수 있도록 hyperparameter를 조정하고자 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueXJsrhNGqlS"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "def get_auc_CV(model):\n",
        "    \"\"\"\n",
        "    Return the average AUC score from cross-validation.\n",
        "    \"\"\"\n",
        "    # Set KFold to shuffle data before the split\n",
        "    kf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
        "\n",
        "    # Get AUC scores\n",
        "    auc = cross_val_score(\n",
        "        model, X_train_tfidf, y_train, scoring=\"roc_auc\", cv=kf)\n",
        "\n",
        "    return auc.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53MgflYPHNxh"
      },
      "source": [
        "Naive Bayes의 `MultinominalNB`는 hyperparameter가 알파 하나이다. 이를 최적의 알파값을 찾기 위해 알파를 조금씩 조정해간다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKatLhhJGzn0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "0e5cf757-bbec-4fa9-eb08-1caea1e82dac"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "res = pd.Series([get_auc_CV(MultinomialNB(i))\n",
        "                 for i in np.arange(1, 10, 0.1)],\n",
        "                index=np.arange(1, 10, 0.1))\n",
        "\n",
        "best_alpha = np.round(res.idxmax(), 2)\n",
        "print('Best alpha: ', best_alpha)\n",
        "\n",
        "plt.plot(res)\n",
        "plt.title('AUC vs. Alpha')\n",
        "plt.xlabel('Alpha')\n",
        "plt.ylabel('AUC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best alpha:  1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5hV1X3v8feHmWFGcA4qMGdaULCpqZ1YRHOCTaPxR6rBaIKKuWJiQtK0pr3a/LgXqz65jS2pJd7aa3ITq7WGBO+N2iRGQxsT4VEJtJIbB1SCRgkhUcEgA6ggUXCG7/1jr8HDMMCAs+ccz/m8nuc8Z5+1f609zyMf19prr62IwMzMLE/DKl0BMzOrfQ4bMzPLncPGzMxy57AxM7PcOWzMzCx3DhszM8udw8asDkn6mKT/GOxtzfbGYWPWD0mLJL0gqbmf8j/tU3aapLVlvyXpU5JWStomaa2kb0v6g6Gqf1ld/kZSSDppqM9tVs5hY9aHpInAKUAAHziIQ3wZ+DTwKeAI4K3APcA5g1PDgZEk4KPA5vRtVjEOG7M9fRT4MfANYOaB7CjpGOAy4OKIeCAitkfEbyLimxHxxX62v0hSZ5+yz0qan5bfJ+kJSVslrZM06wCqcwrwW2ShN0PS8H3UO1JrbI2kjZL+QdKwPttcn1p7v5R0dln5xyX9LNVxjaRPHkAdrU44bMz29FHgm+nzXknFA9j3PcDaiPjJALf/N+D3Ukj1+hBwe1r+GvDJiGgFjgMeOIC6zEzH/1b6/f79bH8+UAJOBKYBf1K27iTgKWAM8D+Br6WWE8AG4FygAHwcuEHSiQdQT6sDDhuzMpJOBiYA34qIZcAvyP7xH6jRwK8HunFE/Ab4HnBxOv8xwLHA/LTJa0CHpEJEvBARywdyXEkjgA8Ct0fEa8B32H9X2nURsTkingG+1Fun5OmI+JeI6AHmkbWYiukavh8Rv4jMj4AFZK0qs10cNma7mwksiIiN6fft7N6V1g009dmniSwUADaR/UN8IG7n9X/YPwTck0IIYDrwPuBpST+S9M4BHvP8VNd70+9vAmdLGruPfZ4tW34a+O2y3+t7F8rqdiiApLMl/VjSZkkvpvqOGWA9rU44bMwSSYcA/wU4VdJ6SeuBzwLHSzo+bfYMMLHPrkeT/eMMcD8wXlLpAE69EBgraTJZ6PR2oRERD0fENKCNbJDBt/o/xB5mkoXBM+k6vk0WivtqpR1ZtnwU8Nz+TpJG690FXA8UI+IwsoDTPne0uuOwMXvdeUAP0AFMTp/fB5bwehfUvwIflzQlDXF+K1kg3QkQET8H/gm4Iw2JHi6pRdIMSVf1d9LUzfVt4B/IRq8tBEj7fljSqLTNFmDn/i5C0jiye0fnll3H8cB17Lsr7QpJh0s6kmw03b/u71zAcKAZ6AK608CBswawn9UZh43Z62YCX4+IZyJife8H+CrwYUmNEXEfcBXwdeAlsv+LnwfcUnacT6V9bgReJLvvcz7Zzfq9uR34Y+DbEdFdVv4R4FeStgB/DnwYQNJRkl6WdFQ/x/oI8GhELOhzHf8bmCTpuL3U4XvAMuBR4PtkgxP2KSK2puv9FvACWctp/j53srokvzzNzCQFcExErK50Xaw2uWVjZma5c9iYmVnucg0bSVMlPSVpdX83RyVNkHS/pBVpzqnxZeuuS3NLrZR0UVn5GZKWp/J5khrL1p0m6VFJj0v60UDrYVbvIkLuQrM85XbPRlIDsAo4E1gLPEw2hccTZdt8G/j3iJgn6Qzg4xHxEUnnAJ8BziYb6bKIbHTNy2RDTN8TEaskzSZ72Oxrkg4DHgKmRsQzktoiYsNA6mFmZvlq3P8mB20KsDoi1gBIupNsCozyf+Q7gP+Wlh8ke46gt3xxGpXTLWkFMDVtsyMiVqXtFgJXk42a+RDw3fT0MxGx4QDqsYcxY8bExIkTD+Kyzczq07JlyzZGRL8PDucZNuPY/YnktWTzK5V7DLiAbJbc84FWSaNT+TWS/hEYAZxOFg4bgUZJpYjoBC7k9QfR3go0SVoEtAJfjojbBliPPUycOJHOzs79bWZmZomkp/e2Ls+wGYhZwFclfQxYDKwDeiJigaR3kHWLdQFLU3lImkE20V8z2RxMPelYjcDbybrbDgGWSvrxgVRG0qXApQBHHdXf4wtmZnYw8gybdew+/cX4VLZLRDxH1rJB0qHA9Ih4Ma27Frg2rbud7L4LEbGUNMmfpLPIWjSQtVg2RcQ2YJukxWRPTa/dXz3K6nML6eG8UqnkB5DMzAZJnqPRHgaOkXR0eo/GDPo8WSxpTNk7M64G5qbyhtSdhqRJwCSyVgyS2tJ3M3AlcHPa/3vAyZIa04y3JwE/G0g9zMwsX7m1bCKiW9LlwH1AAzA3Ih5PI8g6I2I+cBowJz29vJjspVOQTRi4JL0uYwtwSdkUHldIOpcsKG+KiAfS+X4m6YfACrL5o26NiJUA/dUjr+s2M7M9ebqavSiVSuEBAmZmAydpWUT0O+O5ZxAwM7PcOWzMzCx3DptBtHNn8NUHfs7iVV2VroqZWVVx2AyiYcPEPy9ewwNPbtj/xmZmdcRhM8iKhRbWv/RqpathZlZVHDaDrL3QwvNbHTZmZuUcNoOsrdDMhi3bK10NM7Oq4rAZZMVCC89veZWdO/38kplZL4fNIGsvtNC9M9j8mx2VroqZWdVw2AyyYqEZwIMEzMzKOGwGWbHQAsAGDxIwM9vFYTPIesNm/UseJGBm1sthM8jGtjYjwfNb3LIxM+vlsBlkTQ3DGD2y2d1oZmZlHDY5KBaaPUDAzKyMwyYH2bM2vmdjZtbLYZOD3gc7zcws47DJQbHQzKZtO9jRvbPSVTEzqwoOmxy0+1kbM7Pd5Bo2kqZKekrSaklX9bN+gqT7Ja2QtEjS+LJ110lamT4XlZWfIWl5Kp8nqTGVnybpJUmPps/ny/b5laSfpvLOPK8ZXn/WxvdtzMwyuYWNpAbgRuBsoAO4WFJHn82uB26LiEnAbGBO2vcc4ERgMnASMEtSQdIwYB4wIyKOA54GZpYdb0lETE6f2X3OdXoqLw3ule6pLU1Zs8H3bczMgHxbNlOA1RGxJiJ2AHcC0/ps0wE8kJYfLFvfASyOiO6I2AasAKYCo4EdEbEqbbcQmJ7jNRyU3m609Q4bMzMg37AZBzxb9nttKiv3GHBBWj4faJU0OpVPlTRC0hjgdOBIYCPQKKm3dXJhKu/1TkmPSfqBpLeVlQewQNIySZfurcKSLpXUKamzq6vrwK62zOEjhtPUIHejmZkllR4gMAs4VdIjwKnAOqAnIhYA9wIPAXcAS1N5ADOAGyT9BNgK9KRjLQcmRMTxwFeAe8rOc3JEnEjWpXeZpHf3V5mIuCUiShFRGjt27EFf1LBhoq3Vw5/NzHrlGTbr2L3VMT6V7RIRz0XEBRFxAvC5VPZi+r423WM5ExCwKpUvjYhTImIKsLisfEtEvJyW7wWaUquIiFiXvjcAd5N18eWqWGh22JiZJXmGzcPAMZKOljScrEUyv3wDSWPSTX+Aq4G5qbwhdachaRIwCViQfrel72bgSuDm9LtdktLylHRtmySNlNSaykcCZwErc7vqxA92mpm9rjGvA0dEt6TLgfuABmBuRDwuaTbQGRHzgdOAOZKCrJVyWdq9CViSsmMLcElEdKd1V0g6lyxMboqI3gEGFwJ/IakbeIVsxFpIKgJ3p2M1ArdHxA/zuu5exUILS36+Me/TmJm9KSi7DWJ9lUql6Ow8+Edyblr0C6774ZOs/Nv3cmhzbpluZlY1JC3b2+MllR4gULPaR2XP2rgrzczMYZObYmvvLAIOGzMzh01O2goOGzOzXg6bnLSP8vxoZma9HDY5ObS5kZHDG9yyMTPDYZOr4ig/a2NmBg6bXBVb/XpoMzNw2OSqWGhm/Utu2ZiZOWxyVBzVwoatr+IHZ82s3jlsclRsbeG1nmDzth2VroqZWUU5bHLk4c9mZhmHTY6K6fXQz2/1fRszq28Omxy19U5Z40ECZlbnHDY5autt2bgbzczqnMMmR82NDRwxcri70cys7jlsclYstLgbzczqnsMmZ8VCs1s2Zlb3HDY5ay+0sP4l37Mxs/rmsMlZW6GFTdu281rPzkpXxcysYnING0lTJT0labWkq/pZP0HS/ZJWSFokaXzZuuskrUyfi8rKz5C0PJXPk9SYyk+T9JKkR9Pn8wOtR56KhWYiYOPLbt2YWf3KLWwkNQA3AmcDHcDFkjr6bHY9cFtETAJmA3PSvucAJwKTgZOAWZIKkoYB84AZEXEc8DQws+x4SyJicvrMPoB65KY9vbHTE3KaWT3Ls2UzBVgdEWsiYgdwJzCtzzYdwANp+cGy9R3A4ojojohtwApgKjAa2BERq9J2C4Hpg1CP3BQLnrLGzCzPsBkHPFv2e20qK/cYcEFaPh9olTQ6lU+VNELSGOB04EhgI9AoqZT2uTCV93qnpMck/UDS2w6gHgBIulRSp6TOrq6uA7nWvXo9bNyyMbP6VekBArOAUyU9ApwKrAN6ImIBcC/wEHAHsDSVBzADuEHST4CtQE861nJgQkQcD3wFuOdAKxMRt0REKSJKY8eOfYOXlhk9cjgNw+SwMbO6lmfYrGP3Vsf4VLZLRDwXERdExAnA51LZi+n72nTv5UxAwKpUvjQiTomIKcDisvItEfFyWr4XaEqtov3WI0/Dhom21mZ3o5lZXcszbB4GjpF0tKThZC2S+eUbSBqTbvoDXA3MTeUNqTsNSZOAScCC9LstfTcDVwI3p9/tkpSWp6Rr2zSQeuStWGhxy8bM6lpjXgeOiG5JlwP3AQ3A3Ih4XNJsoDMi5gOnAXMkBVkr5bK0exOwJGXHFuCSiOhO666QdC5ZmNwUEb0DDC4E/kJSN/AK2Yi1APqtR17X3Z9ioZk1XduG8pRmZlVFfmVx/0qlUnR2dg7Ksa753krufmQdK/7mvYNyPDOzaiRpWUSU+ltX6QECdaGt0MKWV7t5ZUfP/jc2M6tBDpsh0O7hz2ZW5xw2Q6D3WZv1Dhszq1MOmyFQ3PXGToeNmdUnh80QKI7KWjYb/KyNmdUph80QaG1u5JCmBnejmVndctgMAUm0j/KDnWZWvxw2QySbssZhY2b1yWEzRLIpa3zPxszqk8NmiPR2o3nGBjOrRw6bIdLW2sz27p289Mprla6KmdmQc9gMkfZRfmOnmdUvh80Q8SwCZlbPHDZDpNiaWjYvOWzMrP44bIZIW5qyZsNWh42Z1R+HzRBpaWrgsBFN7kYzs7rksBlC7X7WxszqlMNmCLUVWtjglo2Z1SGHzRAqtja7G83M6lKuYSNpqqSnJK2WdFU/6ydIul/SCkmLJI0vW3edpJXpc1FZ+RmSlqfyeZIa+xzzHZK6JV1YVtYj6dH0mZ/X9e5P+6gWurZup2enZxEws/qSW9hIagBuBM4GOoCLJXX02ex64LaImATMBuakfc8BTgQmAycBsyQVJA0D5gEzIuI44GlgZp9zXgcs6HOeVyJicvp8YJAvdcDaCi3sDNj4su/bmFl9ybNlMwVYHRFrImIHcCcwrc82HcADafnBsvUdwOKI6I6IbcAKYCowGtgREavSdguB6WXH+0vgLmDDYF/MYGgv9M4i4K40M6sveYbNOODZst9rU1m5x4AL0vL5QKuk0al8qqQRksYApwNHAhuBRkmltM+FqRxJ49IxbuqnLi2SOiX9WNJ5e6uwpEvTdp1dXV0Hcq0D8vrrod2yMbP6UukBArOAUyU9ApwKrAN6ImIBcC/wEHAHsDSVBzADuEHST4CtQE861peAKyNiZz/nmRARJeBDwJckvaW/ykTELRFRiojS2LFjB+8qE09ZY2b1qnH/mxy0daRWRzI+le0SEc+RWjaSDgWmR8SLad21wLVp3e3AqlS+FDgllZ8FvDUdrgTcKQlgDPA+Sd0RcU9ErEv7rpG0CDgB+MUgX+9+jTm0mWHCw5/NrO7k2bJ5GDhG0tGShpO1SHYbCSZpTLrpD3A1MDeVN6TuNCRNAiaRbvpLakvfzcCVwM0AEXF0REyMiInAd4D/GhH3SDo8bUvqknsX8ER+l713DcPE2NZm1nt+NDOrM7m1bCKiW9LlwH1AAzA3Ih6XNBvojIj5wGnAHEkBLAYuS7s3AUtSK2ULcElEdKd1V0g6lywob4qIB9i33wf+WdLOtM8XI6IiYQPpjZ1bfc/GzOqL/ObI/pVKpejs7Bz04/7ZbZ08u/k3/PAz7x70Y5uZVZKkZen++B4qPUCg7hQLnkXAzOqPw2aItRdaePE3r/Hqaz3739jMrEY4bIZYWxr+3OX7NmZWRxw2Q8zP2phZPXLYDDFPWWNm9chhM8R6p6zxszZmVk8cNkNs1CFNNDcOY4Pv2ZhZHXHYDDFJ2YOd7kYzszrisKmAYsFT1phZfXHYVECx0OJuNDOrK3sNG0nvLX+1cln5hZLOzLdata1YaGH9S6/iqYLMrF7sq2XzeeBH/ZQvInuFsx2kYqGZV17rYev27v1vbGZWA/YVNs0RscfrKiNiIzAyvyrVvt4HO/1eGzOrF/sKm4KkPV5BIKkJOCS/KtW+XbMIvOT7NmZWH/YVNt8F/kXSrlZMepvmzWmdHSTPImBm9WZfYfM/gOeBpyUtk7Qc+CXQldbZQWrrnUXAYWNmdWKvb+pMb8a8StLfAr+bildHxCtDUrMaNmJ4I60tjb5nY2Z1Y69hI+mCPkUBHCbp0YjYmm+1al97oYXnt/iejZnVh72GDfD+fsqOACZJ+kREPJBTnepCsdDibjQzqxt7vWcTER/v5zMNOA2YM5CDS5oq6SlJqyVd1c/6CZLul7RC0iJJ48vWXSdpZfpcVFZ+hqTlqXxe3xFzkt4hqbv8gVRJMyX9PH1mDqTueSsWWtyNZmZ144Cnq4mIp4Gm/W0nqQG4ETgb6AAultTRZ7PrgdsiYhLZg6Jz0r7nACcCk4GTgFmSCpKGAfOAGRFxHPA0sCs80jmvAxaUlR0BXJOOMwW4RtLhB3rdg61YaGbD1u3s3OlZBMys9h1w2Eg6FhjIzYYpZAMK1kTEDuBOYFqfbTqA3u64B8vWdwCLI6I7IrYBK4CpwGhgR0SsStstBKaXHe8vgbuADWVl7wUWRsTmiHgh7TN1APXPVbHQQvfOYNO2HZWuiplZ7vY1QODfyAYFlDsC+C3gkgEcexzwbNnvtWSti3KPARcAXwbOB1oljU7l10j6R2AEcDrwBLARaJRUiohO4ELgyFTfcekYpwPv2E89xvVXYUmXApcCHHXUUQO4xINXLHvWZmxrc67nMjOrtH0NELi+z+8ANpMFziXA0kE4/yzgq5I+BiwG1gE9EbFA0juAh8ie61maykPSDOAGSc1k3WU96VhfAq6MiJ2SDqoyEXELcAtAqVTKtX+r942dz295lePGjcrzVGZmFbev52x2TcIp6QTgQ8AHyR7svGsAx15HanUk41NZ+TmeI2vZ9M5OMD0iXkzrrgWuTetuB1al8qXAKan8LOCt6XAl4M4UNGOA90nqTuc8rU89Fg2g/rlqH9XbsvHwZzOrffvqRnsrcHH6bAT+FVBEnD7AYz8MHCPpaLJ/8GeQBVb5OcYAmyNiJ3A1MDeVNwCHRcQmSZOASaSb/pLaImJDatlcSQqkiDi67LjfAP49Iu5JAwT+vmxQwFnpXBU15tBmJM8iYGb1YV/daE8CS4BzI2I1gKTPDvTAEdEt6XLgPqABmBsRj0uaDXRGxHzSMGpJQdaNdlnavQlYklopW4BL0owGAFdIOpdscMNN+3veJyI2S/oCWfgBzI6IzQO9jrw0NQxj9MhmD382s7qgvb3AS9J5ZK2RdwE/JBtNdmt5C6KWlUql6OzszPUc535lCWMPbebrH5+S63nMzIaCpGURUepv3b4e6rwnImYAx5INS/4M0CbppnSvxN6gYmsL633PxszqwH6fs4mIbRFxe0S8n+zm+iNk90rsDSqO8iwCZlYfDuihzoh4ISJuiYj35FWhelJsbWHTth1s7+7Z/8ZmZm9iBzyDgA2e9lHZszZdW92VZma1zWFTQW0FP2tjZvXBYVNBxVa/HtrM6oPDpoJen0XAYWNmtc1hU0GHj2hieMMwzyJgZjXPYVNBkmgrNLPB92zMrMY5bCqsWGhxN5qZ1TyHTYUVC83uRjOzmuewqbBiocXdaGZW8xw2FVYstPDy9m5e3t69/43NzN6kHDYV1l7w8Gczq30Omwpr63099EsOGzOrXQ6bCtvVstnqsDGz2uWwqTDPj2Zm9cBhU2GHNjdyaHMj692NZmY1LNewkTRV0lOSVku6qp/1EyTdL2mFpEWSxpetu07SyvS5qKz8DEnLU/k8SY2pfFo6zqOSOiWdXLZPTyp/VNL8PK/5YBQLzWxwN5qZ1bDcwkZSA3AjcDbQAVwsqaPPZtcDt0XEJGA2MCftew5wIjAZOAmYJakgaRgwD5gREccBTwMz07HuB46PiMnAnwC3lp3nlYiYnD4fyOFy35BiocUtGzOraXm2bKYAqyNiTUTsAO4EpvXZpgN4IC0/WLa+A1gcEd0RsQ1YAUwFRgM7ImJV2m4hMB0gIl6OiEjlI4He5arXXmjxPRszq2l5hs044Nmy32tTWbnHgAvS8vlAq6TRqXyqpBGSxgCnA0cCG4FGSaW0z4WpHABJ50t6Evg+WeumV0vqWvuxpPP2VmFJl6btOru6ug70eg9aW6GFDVtf5fWsNDOrLZUeIDALOFXSI8CpwDqgJyIWAPcCDwF3AEtTeQAzgBsk/QTYCvT0Hiwi7o6IY4HzgC+UnWdCRJSADwFfkvSW/ioTEbdERCkiSmPHjh3sa92rYqGZ13qCzdt2DNk5zcyGUmOOx15HWasDGJ/KdomI50gtG0mHAtMj4sW07lrg2rTudmBVKl8KnJLKzwLe2vfEEbFY0u9IGhMRGyNiXSpfI2kRcALwi8G71Dem91mb93/lP2hqzPL/k+9+Cx866ahKVsvMbNDk2bJ5GDhG0tGShpO1SHYbCSZpTLrpD3A1MDeVN6TuNCRNAiYBC9LvtvTdDFwJ3Jx+/64kpeUTgWZgk6TD07akLrl3AU/kdtUH4Y/eMoaLpxzJlKOP4IQjD2Prq90sfGJ9patlZjZocmvZRES3pMuB+4AGYG5EPC5pNtAZEfOB04A5kgJYDFyWdm8ClqTs2AJcEhG9M1VeIelcsqC8KSJ6BxhMBz4q6TXgFeCiiAhJvw/8s6SdaZ8vRkRVhc2oEU3MuWDSrt9/Ou9h1r3o0WlmVjvkm9L9K5VK0dnZWZFzf+7un/KDletZ/tdnVuT8ZmYHQ9KydH98D5UeIGD9aC+0sHnbDrZ39+x/YzOzNwGHTRUqjsoGDPilamZWKxw2Vah3dJpfF21mtcJhU4XaU8vGU9iYWa1w2FShot/eaWY1xmFThQotjRzS1OCWjZnVDIdNFZJEsdDsezZmVjMcNlWqWGhxN5qZ1QyHTZVqH9Xilo2Z1QyHTZXqfceNZ3gws1rgsKlSxUILO7p38sJvXqt0VczM3jCHTZXyszZmVkscNlXKz9qYWS1x2FSpXS0bh42Z1QCHTZVqa21GcjeamdUGh02VamoYxuiRzWzY6rAxszc/h00Vax/V7JaNmdUEh00Vay+0sN7vtDGzGuCwqWJtnrLGzGpErmEjaaqkpyStlnRVP+snSLpf0gpJiySNL1t3naSV6XNRWfkZkpan8nmSGlP5tHScRyV1Sjq5bJ+Zkn6ePjPzvObB5NdDm1mtyC1sJDUANwJnAx3AxZI6+mx2PXBbREwCZgNz0r7nACcCk4GTgFmSCpKGAfOAGRFxHPA00Bse9wPHR8Rk4E+AW9OxjgCuSceZAlwj6fB8rnpw9b6x06+HNrM3uzxbNlOA1RGxJiJ2AHcC0/ps0wE8kJYfLFvfASyOiO6I2AasAKYCo4EdEbEqbbcQmA4QES/H6xOJjQR6l98LLIyIzRHxQtpn6iBeZ26KftbGzGpEnmEzDni27PfaVFbuMeCCtHw+0CppdCqfKmmEpDHA6cCRwEagUVIp7XNhKgdA0vmSngS+T9a6GWg9eve/NHXBdXZ1dR3Qxeaht2XjEWlm9mZX6QECs4BTJT0CnAqsA3oiYgFwL/AQcAewNJUHMAO4QdJPgK3ArhsaEXF3RBwLnAd84UArExG3REQpIkpjx459g5f2xrV7yhozqxF5hs06ylodwPhUtktEPBcRF0TECcDnUtmL6fvaiJgcEWcCAlal8qURcUpETAEW95b3Oe5i4HdSq2i/9ahWhUMaaWka5paNmb3p5Rk2DwPHSDpa0nCyFsn88g0kjUk3/QGuBuam8obUnYakScAkYEH63Za+m4ErgZvT79+VpLR8ItAMbALuA86SdHgaGHBWKqt6ktKzNg4bM3tza8zrwBHRLelysn/YG4C5EfG4pNlAZ0TMB04D5kgKslbKZWn3JmBJyo4twCUR0Z3WXSHpXLKgvCkiegcYTAc+Kuk14BXgotTttlnSF8jCD2B2RGzO67oHm18PbWa1QH4TZP9KpVJ0dnZWuhp8+s5HWP7MCyz5qzMqXRUzs32StCwiSv2ty61lY4OjvdDC8y9tZ/5jz+132+bGYZxxbBtNDZUe92FmtjuHTZV7S9uh7OjZyafueGRA2998yduZelx7zrUyMzswDpsq98G3j2fKxCPo3rnv7s6Xt3dz3o3/ydoXfjNENTMzGziHTZWTxMQxI/e7XUQwvHGYBxOYWVVy536NeH2YtOdRM7Pq47CpIe0eJm1mVcphU0OKoxw2ZladHDY1pL2QvUbaz06ZWbVx2NSQYqGF7d07eemV1ypdFTOz3Thsaki7339jZlXKYVND/P4bM6tWDpsaUvT7b8ysSjlsakhxV8vGz9qYWXVx2NSQ4Y3DGD1yuO/ZmFnVcdjUGL//xsyqkcOmxrSPavEAATOrOg6bGuOWjZlVI4dNjWkvtLBp2w62d/dUuipmZrs4bGpMsdAMwAbP/mxmVSTXsJE0VdJTklZLuqqf9RMk3S9phaRFksaXrbtO0sr0uais/AxJy1P5PEmNqfzD6Tg/lfSQpOPL9vlVKn9UUmee11xpxVF+1sbMqk9uYSOpAUOepzAAAAeUSURBVLgROBvoAC6W1NFns+uB2yJiEjAbmJP2PQc4EZgMnATMklSQNAyYB8yIiOOAp4GZ6Vi/BE6NiD8AvgDc0udcp0fE5IgoDfKlVpVdswg4bMysiuTZspkCrI6INRGxA7gTmNZnmw7ggbT8YNn6DmBxRHRHxDZgBTAVGA3siIhVabuFwHSAiHgoIl5I5T8GdrWS6omnrDGzapRn2IwDni37vTaVlXsMuCAtnw+0ShqdyqdKGiFpDHA6cCSwEWiU1Ns6uTCV9/UJ4AdlvwNYIGmZpEv3VmFJl0rqlNTZ1dU1oIusNoeNaPLroc2s6jRW+PyzgK9K+hiwGFgH9ETEAknvAB4CuoClqTwkzQBukNQMLAB2G3Yl6XSysDm5rPjkiFgnqQ1YKOnJiFjctzIRcQup+61UKr0pXwrT+3ro5z1AwMyqSJ4tm3Xs3uoYn8p2iYjnIuKCiDgB+FwqezF9X5vusZwJCFiVypdGxCkRMYUsoHq71JA0CbgVmBYRm8rOsy59bwDuJuviq1nthRbfszGzqpJn2DwMHCPpaEnDgRnA/PINJI1JN/0BrgbmpvKG1J3WGyCTyFoxpNYJqWVzJXBz+n0U8F3gI2X3dJA0UlJr7zJwFrAylyuuEn49tJlVm9y60SKiW9LlwH1AAzA3Ih6XNBvojIj5wGnAHElB1kq5LO3eBCyRBLAFuCQiutO6KySdSxaUN0VE7wCDz5MNIPintF93GnlWBO5OZY3A7RHxw7yuuxq0F5pZkF4Pna7bzKyi5PfV969UKkVn55vzkZxbl6zh777/Mx79/JkcNmJ4patjZnVC0rK9PV7iGQRqkF8PbWbVxmFTg/ysjZlVG4dNDfLroc2s2jhsapBfD21m1cZhU4P8emgzqzaVnkHAclIstPBvjz1H5682V7oqZvYmcviI4Xzrz9856Md12NSoT576O9z3+PpKV8PM3mQKLU25HNdhU6OmTR7HtMl95z01M6sM37MxM7PcOWzMzCx3DhszM8udw8bMzHLnsDEzs9w5bMzMLHcOGzMzy53DxszMcueXp+2FpC7g6UrX4w0aA2ysdCWqiP8ee/LfZHf+e+zpQP4mEyJibH8rHDY1TFLn3t6aV4/899iT/ya7899jT4P1N3E3mpmZ5c5hY2ZmuXPY1LZbKl2BKuO/x578N9md/x57GpS/ie/ZmJlZ7tyyMTOz3DlszMwsdw6bGiTpSEkPSnpC0uOSPl3pOlUDSQ2SHpH075WuS6VJOkzSdyQ9Kelnkgb/PcBvMpI+m/57WSnpDkktla7TUJI0V9IGSSvLyo6QtFDSz9P34Qd7fIdNbeoG/ntEdAB/CFwmqaPCdaoGnwZ+VulKVIkvAz+MiGOB46nzv4ukccCngFJEHAc0ADMqW6sh9w1gap+yq4D7I+IY4P70+6A4bGpQRPw6Ipan5a1k/5DU9TuiJY0HzgFurXRdKk3SKODdwNcAImJHRLxY2VpVhUbgEEmNwAjguQrXZ0hFxGJgc5/iacC8tDwPOO9gj++wqXGSJgInAP+vsjWpuC8BfwXsrHRFqsDRQBfw9dSteKukkZWuVCVFxDrgeuAZ4NfASxGxoLK1qgrFiPh1Wl4PFA/2QA6bGibpUOAu4DMRsaXS9akUSecCGyJiWaXrUiUagROBmyLiBGAbb6B7pBakexHTyIL4t4GRki6pbK2qS2TPyRz0szIOmxolqYksaL4ZEd+tdH0q7F3AByT9CrgTOEPS/61slSpqLbA2Inpbu98hC5969sfALyOiKyJeA74L/FGF61QNnpf0WwDpe8PBHshhU4Mkiaw//mcR8b8qXZ9Ki4irI2J8REwku+n7QETU7f+1RsR64FlJv5eK3gM8UcEqVYNngD+UNCL99/Me6nzQRDIfmJmWZwLfO9gDOWxq07uAj5D9H/yj6fO+SlfKqspfAt+UtAKYDPx9hetTUamV9x1gOfBTsn8b62rqGkl3AEuB35O0VtIngC8CZ0r6OVnr74sHfXxPV2NmZnlzy8bMzHLnsDEzs9w5bMzMLHcOGzMzy53DxszMcuewMaswSedJCknHpt8Ty2fe3cs++93GrJo4bMwq72LgP9K3WU1y2JhVUJq/7mTgE/Qzpb2kj0n6nqRF6Z0i15StbpD0L+kdLAskHZL2+TNJD0t6TNJdkkYMzdWY7Z3DxqyyppG9V2YVsEnS2/vZZgowHZgEfFBSKZUfA9wYEW8DXkzbAHw3It4REb3vqflErldgNgAOG7PKuphsclDSd39daQsjYlNEvEI2QeTJqfyXEfFoWl4GTEzLx0laIumnwIeBt+VSc7MD0FjpCpjVK0lHAGcAfyApyN4OGcCNfTbtO6dU7+/tZWU9wCFp+RvAeRHxmKSPAacNXq3NDo5bNmaVcyHwfyJiQkRMjIgjgV8CR/bZ7sz0LvhDyN6U+J/7OW4r8Ov0mokPD3qtzQ6Cw8asci4G7u5TdhdwdZ+yn6TyFcBdEdG5n+P+NdmbWf8TeHIQ6mn2hnnWZ7MqlrrBShFxeaXrYvZGuGVjZma5c8vGzMxy55aNmZnlzmFjZma5c9iYmVnuHDZmZpY7h42ZmeXu/wOOcXT2ReeU+QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaATcy1nIeE9"
      },
      "source": [
        "### 2.2. Evaluation on Validation Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne-eoqM4Muna"
      },
      "source": [
        "Validation Set를 통해 성능을 평가하기 위해 AUC아 Accuracy Score를 활용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qS2gb-9mJK2w"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
        "\n",
        "def evaluate_roc(probs, y_true):\n",
        "    \"\"\"\n",
        "    - Print AUC and accuracy on the test set\n",
        "    - Plot ROC\n",
        "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
        "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
        "    \"\"\"\n",
        "    preds = probs[:, 1]\n",
        "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(f'AUC: {roc_auc:.4f}')\n",
        "       \n",
        "    # Get accuracy over the test set\n",
        "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
        "    \n",
        "    # Plot ROC AUC\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnCfezJSM-41"
      },
      "source": [
        "이렇게 TF-IDF와 Naive Bayes모델을 활용하여 나온 성능은 **74.24%**이다. 이 수치는 BERT를 활용한 모델이 넘어야 할 베이스라인으로 잡을 것이다.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwVGbLHLIwpl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "ccda8fe3-165a-4bc1-9c88-cd60339d2e3c"
      },
      "source": [
        "# Compute predicted probabilities\n",
        "nb_model = MultinomialNB(alpha=1.8)\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "probs = nb_model.predict_proba(X_test_tfidf)\n",
        "\n",
        "# Evaluate the classifier\n",
        "evaluate_roc(probs, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.9897\n",
            "Accuracy: 74.24%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEPPYHa62JXF"
      },
      "source": [
        "# D - Fine-tuning BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYJRzWI73eBJ"
      },
      "source": [
        "## 1. Install the Hugging Face Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxv-EJ2j31Iv"
      },
      "source": [
        "Hugging Face의 Library를 활용하면, Pytorch 프레임워크로 이용할 수 있는 BERT, GPT 등의 모델및 사전학습된 가중치들을 활용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFiv8WGl4p40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a12c6bdf-24f9-49ca-e511-b599add81905"
      },
      "source": [
        "!pip install transformers==2.8.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 7.8MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/e3/5e49e9a83fb605aaa34a1c1173e607302fecae529428c28696fb18f1c2c9/tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6MB 8.6MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/10/a997a266165e2df1976c4fc973f71bcd2e65a255f92d0ff7ab59b2f81989/boto3-1.17.44-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 45.0MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 59.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0) (2019.12.20)\n",
            "Collecting botocore<1.21.0,>=1.20.44\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/80/3ddbe4ad2561804b887deb8072d802dc24dd759833139a5b91efcff308d6/botocore-1.20.44-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 49.3MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/14/0b4be62b65c52d6d1c442f24e02d2a9889a73d3c352002e14c70f84a679f/s3transfer-0.3.6-py2.py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.44->boto3->transformers==2.8.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=df7158b62d0846a52bae9886d87d81e65948461e597015b70d42e93c2e33b9fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: botocore 1.20.44 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, jmespath, botocore, s3transfer, boto3, sacremoses, sentencepiece, transformers\n",
            "Successfully installed boto3-1.17.44 botocore-1.20.44 jmespath-0.10.0 s3transfer-0.3.6 sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4sXctSh4sq0"
      },
      "source": [
        "## 2. Tokenization and Input Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygbZpK6qbIYE"
      },
      "source": [
        "문장들을 토큰화하기 전에 특수기호 제거 및 쓸데 없는 띄어쓰기를 제거하도록 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L_Rc7l4bgzJ"
      },
      "source": [
        "def text_preprocessing(text):\n",
        "    \"\"\"\n",
        "    - Remove entity mentions (eg. '@united')\n",
        "    - Correct errors (eg. '&amp;' to '&')\n",
        "    @param    text (str): a string to be processed.\n",
        "    @return   text (Str): the processed string.\n",
        "    \"\"\"\n",
        "    # Remove '@name'\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyYmHR8McE0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caf696bd-fe7e-4634-9b35-408e41bf03c8"
      },
      "source": [
        "# Print sentence 0\n",
        "print('Original: ', X[0])\n",
        "print('Processed: ', text_preprocessing(X[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:                                The Promised Neverland nd Season is a brilliant achievement of Japanese Television It is a series that has no reason to exist other than to profit off of unsuspecting fans of the first season This is the spiritual successor to Tokyo Ghoul Root Aanother anime original sequel that attempted to inflict as much severe pain and suffering on the manga fans as possible Except at least that blatant marketing scheme had semidecent audiovisuals This sequel follows Female Kirito previously known as Emma Similar to Kirito Emma is also the most powerful player in the video game Rather than using a sword she has the power                  of plot armor to protect her from any danger Getting chased by a demon She can outrun it Armed soldiers cant kill demons with guns Shell kill it with a bow  arrow Instead of getting followed around by a harem Female Kirito has a bunch of children that go along with anything she says They have names but dont worryyou wont remember them anyway Previously a character known as Ray challenged Emmas overly idealistic goals This season he has been renamed to Hay because has no weight on the plot and allows Emma to do anythingno matter how stupid she acts A longlost friend who was lost for less than  episodes returns but hes actually a bitter Bad Guy now Shocking But why is he bad He explains everything to us because we are incapable of comprehending storytellingwe must be fucking idiots Just sit back and get spoonfed by one of Season Twos many iconic exposition scenes Emma and her harem gather in a nondescript room and one character standsup and summarizes  chapters of the manga in a five to tenminute long speech Its like karaoke night but instead of singing they monotonously read SparkNotes summaries of the manga with no animation whatsoever Unless you consider a PowerPoint presentation to be animation The Promised Neverland nd Season does not tell a story nor does it do much of anything It uses a bunch of unrelated plot points throughout dozens of chapters Years of time skips pass by in minutes Then it stitches these barely connected pieces together like a hideous quilt The entire show rides on how Emmas feeling today In one episode shell let the kids eat potentially poisonous fish in the other shell happily help a demon with its groceries despite knowing they like to eat children for supper No matter anything she does shell have either a smile on her face or a slightly concerned expression I dont like comparing the adaptation to the manga but in this case it is impossible to not notice the differences in art detail and writing quality All of the passion is drained turning climactic moments into laughably bad dialogue Villains doublecross each other in unison like a hive mind being controlled by an annoyed writer They should have explained the motivations behind everyones sudden changes in goals and morality but thatd require hard work And lazy writers dont like doing hard work Why bother adapting three beloved story arcs from the mangafull of battles that would be VERY expensive to animatewhen you can just summarize them with a PowerPoint presentation Thats easy money Strip away the psychological horror intelligence atmosphere and logic that made the original anime so special and what do you have left This piece of inane shit Granted I am not a huge fan of the original but it was lightyears better than this The show is dependent upon the demon creature effects but even in D they are below average at best Its remarkable really CloverWorks has mastered the art of being lazy and they should be applauded for thatMy instinct is to blame the writers at Cloverworks but its clear from disappearing names in the credits that they did not want to be associated with this colossal dumpster fire According to interviews the mangaka cowrote the anime original story but that has never stopped a film from being bad George Lucas cowrote The Rise of the Skywalker and George RR Martin worked on the clusterfuck that was Game of Thrones S Just like those adaptations The Promised Neverland will go down as one of the greatest declines in writing quality in all of anime history The last time I saw an anime crash and burn so hard in the final act was Darling in the FranXX Thats all there is to The Promised Neverland nd season Finishing as quickly as possible to cash a paycheck Every aspect of it is rushed The stiff voice performances the recycled soundtrack is poorly mixed They reuse the same facial expressions character animations background art and CGI monsters Even to the untrained eye it will be obvious the production has cut corners in literally every aspect If you dont care about quality and want your intelligence to be insulted watch this remarkable landmark in anime history Come along join these personified potatoes on a journey to rebel against Weekly Shounen Jump by becoming the most profitable adaptation while putting in the least amount of talent  budget possible A journey which they have failed apparently according to the abysmal sales        \n",
            "Processed:  The Promised Neverland nd Season is a brilliant achievement of Japanese Television It is a series that has no reason to exist other than to profit off of unsuspecting fans of the first season This is the spiritual successor to Tokyo Ghoul Root Aanother anime original sequel that attempted to inflict as much severe pain and suffering on the manga fans as possible Except at least that blatant marketing scheme had semidecent audiovisuals This sequel follows Female Kirito previously known as Emma Similar to Kirito Emma is also the most powerful player in the video game Rather than using a sword she has the power of plot armor to protect her from any danger Getting chased by a demon She can outrun it Armed soldiers cant kill demons with guns Shell kill it with a bow arrow Instead of getting followed around by a harem Female Kirito has a bunch of children that go along with anything she says They have names but dont worryyou wont remember them anyway Previously a character known as Ray challenged Emmas overly idealistic goals This season he has been renamed to Hay because has no weight on the plot and allows Emma to do anythingno matter how stupid she acts A longlost friend who was lost for less than episodes returns but hes actually a bitter Bad Guy now Shocking But why is he bad He explains everything to us because we are incapable of comprehending storytellingwe must be fucking idiots Just sit back and get spoonfed by one of Season Twos many iconic exposition scenes Emma and her harem gather in a nondescript room and one character standsup and summarizes chapters of the manga in a five to tenminute long speech Its like karaoke night but instead of singing they monotonously read SparkNotes summaries of the manga with no animation whatsoever Unless you consider a PowerPoint presentation to be animation The Promised Neverland nd Season does not tell a story nor does it do much of anything It uses a bunch of unrelated plot points throughout dozens of chapters Years of time skips pass by in minutes Then it stitches these barely connected pieces together like a hideous quilt The entire show rides on how Emmas feeling today In one episode shell let the kids eat potentially poisonous fish in the other shell happily help a demon with its groceries despite knowing they like to eat children for supper No matter anything she does shell have either a smile on her face or a slightly concerned expression I dont like comparing the adaptation to the manga but in this case it is impossible to not notice the differences in art detail and writing quality All of the passion is drained turning climactic moments into laughably bad dialogue Villains doublecross each other in unison like a hive mind being controlled by an annoyed writer They should have explained the motivations behind everyones sudden changes in goals and morality but thatd require hard work And lazy writers dont like doing hard work Why bother adapting three beloved story arcs from the mangafull of battles that would be VERY expensive to animatewhen you can just summarize them with a PowerPoint presentation Thats easy money Strip away the psychological horror intelligence atmosphere and logic that made the original anime so special and what do you have left This piece of inane shit Granted I am not a huge fan of the original but it was lightyears better than this The show is dependent upon the demon creature effects but even in D they are below average at best Its remarkable really CloverWorks has mastered the art of being lazy and they should be applauded for thatMy instinct is to blame the writers at Cloverworks but its clear from disappearing names in the credits that they did not want to be associated with this colossal dumpster fire According to interviews the mangaka cowrote the anime original story but that has never stopped a film from being bad George Lucas cowrote The Rise of the Skywalker and George RR Martin worked on the clusterfuck that was Game of Thrones S Just like those adaptations The Promised Neverland will go down as one of the greatest declines in writing quality in all of anime history The last time I saw an anime crash and burn so hard in the final act was Darling in the FranXX Thats all there is to The Promised Neverland nd season Finishing as quickly as possible to cash a paycheck Every aspect of it is rushed The stiff voice performances the recycled soundtrack is poorly mixed They reuse the same facial expressions character animations background art and CGI monsters Even to the untrained eye it will be obvious the production has cut corners in literally every aspect If you dont care about quality and want your intelligence to be insulted watch this remarkable landmark in anime history Come along join these personified potatoes on a journey to rebel against Weekly Shounen Jump by becoming the most profitable adaptation while putting in the least amount of talent budget possible A journey which they have failed apparently according to the abysmal sales\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3acv6s95YYr"
      },
      "source": [
        "### 2.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1fRHtdU5dEn"
      },
      "source": [
        "In order to apply the pre-trained BERT, we must use the tokenizer provided by the library. This is because (1) the model has a specific, fixed vocabulary and (2) the BERT tokenizer has a particular way of handling out-of-vocabulary words.\n",
        "\n",
        "In addition, we are required to add special tokens to the start and end of each sentence, pad & truncate all sentences to a single constant length, and explicitly specify what are padding tokens with the \"attention mask\".\n",
        "\n",
        "The `encode_plus` method of BERT tokenizer will:\n",
        "\n",
        "(1) split our text into tokens,(텍스트를 정해진 토큰단위로 나눈다)\n",
        "\n",
        "(2) add the special `[CLS]` and `[SEP]` tokens, and([CLS], 및 [SEP] 토큰을 추가한다)\n",
        "\n",
        "(3) convert these tokens into indexes of the tokenizer vocabulary,(토큰화 어휘록에 내재되어 있는 인덱스로 전환한다)\n",
        "\n",
        "(4) pad or truncate sentences to max length, and(max length(최대길이)로 맞추기 위해 문장들에 패딩을 추가하거나, 길이를 줄인다)\n",
        "\n",
        "(5) create attention mask.(어텐션 마스크를 추가한다(예측해야 할 다음 단어들을 마스킹한다))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDAfbCle59tP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68,
          "referenced_widgets": [
            "c7da066509e548a4b2b756eeb5536759",
            "6ddc1ea05a5b4e028312519ed54db10a",
            "62fbd8a16f9f4e52b06f95f36fc89419",
            "b38b73520a8f4731a498bfaa505e7281",
            "d0e48e5c7cd84d629ed330d78519426c",
            "801703a7905a489aa58a7ac644630c57",
            "6401d37d85d942018cb14436fc202630",
            "1df0e23b6dc641c8b3d7ceeefa048171"
          ]
        },
        "outputId": "a61e16c1-04c2-4ae9-fb23-dfa1868a87db"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# Create a function to tokenize a set of texts\n",
        "def preprocessing_for_bert(data):\n",
        "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
        "    @param    data (np.array): Array of texts to be processed.\n",
        "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
        "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
        "                  tokens should be attended to by the model.\n",
        "    \"\"\"\n",
        "    # Create empty lists to store outputs\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    # For every sentence...\n",
        "    for sent in data:\n",
        "        # `encode_plus` will:\n",
        "        #    (1) Tokenize the sentence\n",
        "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "        #    (3) Truncate/Pad sentence to max length\n",
        "        #    (4) Map tokens to their IDs\n",
        "        #    (5) Create attention mask\n",
        "        #    (6) Return a dictionary of outputs\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  # Preprocess sentence\n",
        "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
        "            pad_to_max_length=True,         # Pad sentence to max length\n",
        "            #return_tensors='pt',           # Return PyTorch tensor\n",
        "            return_attention_mask=True      # Return attention mask\n",
        "            )\n",
        "        \n",
        "        # Add the outputs to the lists\n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7da066509e548a4b2b756eeb5536759",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNE9oASMZ1bN"
      },
      "source": [
        "문장의 최대길이를 설정해야 한다. 해당 리뷰들은 애니메이션에 대한 감상평을 굉장히 상세하게 기재하여서, 한문장 한문장의 길이가 모델에서 수용할 수 있는 최대길이를 거뜬히 넘어가는 경향이 있다(최대길이 512)) 단어들이 임베딩 될때 전체적인 의미가 내포되지 않을 가능성도 있을 듯하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrbvKGNAlMtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d76aa2-860a-4315-f649-99296276a102"
      },
      "source": [
        "# Concatenate train data and test data\n",
        "all_review = np.concatenate([data.review.values, test_data.review.values])\n",
        "\n",
        "# Encode our concatenated data\n",
        "encoded_review = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_review]\n",
        "\n",
        "# Find the maximum length\n",
        "max_len = max([len(sent) for sent in encoded_review])\n",
        "print('Max length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (955 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (649 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (947 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (650 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3766 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2510 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2098 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1150 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (639 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (716 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2313 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1595 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (844 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (711 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (865 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2087 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1512 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1254 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1345 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1028 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (781 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1045 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1493 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1508 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (978 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (824 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (736 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (686 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (588 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (892 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (839 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (622 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (976 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1096 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1728 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3255 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2444 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1129 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (939 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1555 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (732 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1298 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (773 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (940 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (559 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1854 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1400 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2043 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (768 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1162 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1278 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2244 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (693 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1962 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (807 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3202 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2411 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1299 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1404 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (628 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3669 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (867 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (643 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1055 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (823 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1038 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (543 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2747 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (909 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1839 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1006 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1657 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (925 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (679 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1213 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2188 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2054 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3014 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1032 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (809 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1108 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2236 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (691 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1381 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2208 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1906 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1469 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1232 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (852 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1727 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (536 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (556 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (632 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (811 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (617 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (683 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1639 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (805 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (729 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (633 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (593 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2204 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (868 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (783 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (581 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1409 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1391 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1745 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1176 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (624 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1148 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (975 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (522 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (739 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1101 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (653 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1371 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (917 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1029 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1646 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (667 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (718 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (529 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1462 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (611 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3810 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (818 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3681 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (641 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (845 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (623 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1335 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (938 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1017 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (689 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2017 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (811 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2702 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1292 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1850 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1048 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1138 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1856 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (833 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3040 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1130 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2520 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3174 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1002 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1408 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1338 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (563 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (673 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (754 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (582 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (551 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (801 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (644 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1178 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1251 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1144 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (676 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (952 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1497 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (912 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (609 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (932 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (654 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2651 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (902 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1840 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1243 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1538 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (516 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1116 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1174 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (832 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (663 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (737 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (988 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (530 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2531 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (595 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (572 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (929 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1031 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (744 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (903 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (811 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1123 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1009 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (517 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1078 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1015 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (964 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (544 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (660 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (858 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1102 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (682 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (554 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2183 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (652 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (721 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1133 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1019 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (511 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1776 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (637 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (906 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (665 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (549 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (950 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1479 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (837 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (973 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1020 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (2069 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (724 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (537 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1058 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (984 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1389 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1034 > 512). Running this sequence through the model will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (587 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max length:  3812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTlQzTzAfCy7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449e0b88-101c-41d1-fa13-31966051ecab"
      },
      "source": [
        "# Specify `MAX_LEN`\n",
        "MAX_LEN = 64\n",
        "\n",
        "# Print sentence 0 and its encoded token ids\n",
        "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "test_inputs, test_masks = preprocessing_for_bert(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:                                The Promised Neverland nd Season is a brilliant achievement of Japanese Television It is a series that has no reason to exist other than to profit off of unsuspecting fans of the first season This is the spiritual successor to Tokyo Ghoul Root Aanother anime original sequel that attempted to inflict as much severe pain and suffering on the manga fans as possible Except at least that blatant marketing scheme had semidecent audiovisuals This sequel follows Female Kirito previously known as Emma Similar to Kirito Emma is also the most powerful player in the video game Rather than using a sword she has the power                  of plot armor to protect her from any danger Getting chased by a demon She can outrun it Armed soldiers cant kill demons with guns Shell kill it with a bow  arrow Instead of getting followed around by a harem Female Kirito has a bunch of children that go along with anything she says They have names but dont worryyou wont remember them anyway Previously a character known as Ray challenged Emmas overly idealistic goals This season he has been renamed to Hay because has no weight on the plot and allows Emma to do anythingno matter how stupid she acts A longlost friend who was lost for less than  episodes returns but hes actually a bitter Bad Guy now Shocking But why is he bad He explains everything to us because we are incapable of comprehending storytellingwe must be fucking idiots Just sit back and get spoonfed by one of Season Twos many iconic exposition scenes Emma and her harem gather in a nondescript room and one character standsup and summarizes  chapters of the manga in a five to tenminute long speech Its like karaoke night but instead of singing they monotonously read SparkNotes summaries of the manga with no animation whatsoever Unless you consider a PowerPoint presentation to be animation The Promised Neverland nd Season does not tell a story nor does it do much of anything It uses a bunch of unrelated plot points throughout dozens of chapters Years of time skips pass by in minutes Then it stitches these barely connected pieces together like a hideous quilt The entire show rides on how Emmas feeling today In one episode shell let the kids eat potentially poisonous fish in the other shell happily help a demon with its groceries despite knowing they like to eat children for supper No matter anything she does shell have either a smile on her face or a slightly concerned expression I dont like comparing the adaptation to the manga but in this case it is impossible to not notice the differences in art detail and writing quality All of the passion is drained turning climactic moments into laughably bad dialogue Villains doublecross each other in unison like a hive mind being controlled by an annoyed writer They should have explained the motivations behind everyones sudden changes in goals and morality but thatd require hard work And lazy writers dont like doing hard work Why bother adapting three beloved story arcs from the mangafull of battles that would be VERY expensive to animatewhen you can just summarize them with a PowerPoint presentation Thats easy money Strip away the psychological horror intelligence atmosphere and logic that made the original anime so special and what do you have left This piece of inane shit Granted I am not a huge fan of the original but it was lightyears better than this The show is dependent upon the demon creature effects but even in D they are below average at best Its remarkable really CloverWorks has mastered the art of being lazy and they should be applauded for thatMy instinct is to blame the writers at Cloverworks but its clear from disappearing names in the credits that they did not want to be associated with this colossal dumpster fire According to interviews the mangaka cowrote the anime original story but that has never stopped a film from being bad George Lucas cowrote The Rise of the Skywalker and George RR Martin worked on the clusterfuck that was Game of Thrones S Just like those adaptations The Promised Neverland will go down as one of the greatest declines in writing quality in all of anime history The last time I saw an anime crash and burn so hard in the final act was Darling in the FranXX Thats all there is to The Promised Neverland nd season Finishing as quickly as possible to cash a paycheck Every aspect of it is rushed The stiff voice performances the recycled soundtrack is poorly mixed They reuse the same facial expressions character animations background art and CGI monsters Even to the untrained eye it will be obvious the production has cut corners in literally every aspect If you dont care about quality and want your intelligence to be insulted watch this remarkable landmark in anime history Come along join these personified potatoes on a journey to rebel against Weekly Shounen Jump by becoming the most profitable adaptation while putting in the least amount of talent  budget possible A journey which they have failed apparently according to the abysmal sales        \n",
            "Token IDs:  [101, 1996, 5763, 2196, 3122, 1050, 2094, 2161, 2003, 1037, 8235, 6344, 1997, 2887, 2547, 2009, 2003, 1037, 2186, 2008, 2038, 2053, 3114, 2000, 4839, 2060, 2084, 2000, 5618, 2125, 1997, 4895, 13203, 5051, 11873, 4599, 1997, 1996, 2034, 2161, 2023, 2003, 1996, 6259, 6332, 2000, 5522, 1043, 6806, 5313, 7117, 9779, 17048, 5886, 8750, 2434, 8297, 2008, 4692, 2000, 1999, 29301, 2004, 102]\n",
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZU8t5VNfvhY"
      },
      "source": [
        "### 2.2. Create PyTorch DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoHdl3gFgMZY"
      },
      "source": [
        "DataLoader를 활용하여 학습연산의 속도를 높일 수 있도록 설정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHuYEc61gcGL"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "test_labels = torch.tensor(y_test)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSRAga-yj17q"
      },
      "source": [
        "## 3. Train Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoOdsDgG8b_Z"
      },
      "source": [
        "### 3.1. Create BertClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA_yESCl5nuK"
      },
      "source": [
        "BERT의 기본적인 구조는 12개의 transformer층으로 구성되어 있고 각 transformer층은 토큰화된 임베딩을 입력값으로 받아서 같은 크기와 같은 갯수의 임베딩을 출력한다. 최종 transformer층에서 나온 출력값은  classifier에 전달될 특징들을 담고 있다.\n",
        "\n",
        "\n",
        "\n",
        "기본적으로 제공되는 BERT Classifier를 사용 할 수도 있지만 우선 자체적인 Classifier Class을 만들어서 진행을 할 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK41aBFSj5jK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119ab1b9-3af0-4e73-938c-52a6d7c4f835"
      },
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        # Instantiate BERT model\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "        # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # Feed input to classifier to compute logits\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 33 µs, sys: 2 µs, total: 35 µs\n",
            "Wall time: 42 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwNrCgPh-yR7"
      },
      "source": [
        "### 3.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6iOXiN8-8gc"
      },
      "source": [
        "모델의 최적화를 위해서 Optimizer를 도입을 할 것이다. BERT의 저자들은 다음과 같은 hyperparameter를 설정하도록 권한다:\n",
        "\n",
        "- Batch size: 16 or 32\n",
        "- Learning rate (Adam): 5e-5, 3e-5 or 2e-5\n",
        "- Number of epochs: 2, 3, 4\n",
        "\n",
        "Huggingface [run_glue.py](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109) (AdamW optimizer를 활용하여 모델 최적화를 할 것이다)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX7su7Q_269U"
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    # Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41DRNjv4B0Ow"
      },
      "source": [
        "### 3.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYU-GQRZG0y8"
      },
      "source": [
        "4번 데이터셋을 통과시켜서(4에포크) 학습을 시킬 것이며, 한번 학습 할 때 마다 교차성능검사를 할 것이다(validation set):\n",
        "\n",
        "Training:\n",
        "- Unpack our data from the dataloader and load the data onto the GPU(GPU에 데이터를 연다)\n",
        "- Zero out gradients calculated in the previous pass(gradient값을 매회 마다 초기화하기)\n",
        "- Perform a forward pass to compute logits and loss(loss를 측정하기 위해서 전진전파를 실행)\n",
        "- Perform a backward pass to compute gradients (`loss.backward()`)(gradient값을 측정하기 위해 역전파실행)\n",
        "- Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"(경사폭증 현상을 막기 위해 최대치를 1로 설정)\n",
        "- Update the model's parameters (`optimizer.step()`)(parameter를 매회마다 조정)\n",
        "- Update the learning rate (`scheduler.step()`)(매회마다 학습률을 조정)\n",
        "\n",
        "Evaluation:\n",
        "- Unpack our data and load onto the GPU\n",
        "- Forward pass(전진전파)\n",
        "- Compute loss and accuracy rate over the validation set(손실과 accuracy를 validation set에서 평가한다)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy4HkhyECibW"
      },
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            test_loss, test_accuracy = evaluate(model, test_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {test_loss:^10.6f} | {test_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, test_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    test_accuracy = []\n",
        "    test_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        test_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        test_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    test_loss = np.mean(test_loss)\n",
        "    test_accuracy = np.mean(test_accuracy)\n",
        "\n",
        "    return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSfTy9LqiFD-"
      },
      "source": [
        "Now, let's start training our BertClassifier!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfYw7dJ0U0v6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567,
          "referenced_widgets": [
            "28500815f96941b4917ced65cd1f511a",
            "0efd5cebf34f4d368de81de442e3b311",
            "f7748a048c86484f898874fdd9f7f0e5",
            "f17b56ffc74443b583e5768b214a79e1",
            "c6f7d85d1b7949fa808373f40d3c3b76",
            "2ea3ef6b3390489e92e071e872c0a25f",
            "7bc69720a39949378f1ef66fab9ad676",
            "f6f6eba277c74a15a392bfb499270053",
            "703607fec0a144488f84b63e2ae16778",
            "0d621caccd3c44d1a7c17d1709278420",
            "d09a75d89fc441249dd9992c871e526c",
            "ac734e662cd94bf5a69259b6d1fa2887",
            "56e0180c76e94d1087a6e27e3ef5cb66",
            "8d032092c2f84d80b4e02640e134c79b",
            "9cb97864edf041cead3a00c102eaffa3",
            "8de5ffe56e854fccb2530bac4e3ec468"
          ]
        },
        "outputId": "eec8bf09-cb0e-4127-e8e1-706e20e1c173"
      },
      "source": [
        "set_seed(42)    # Set seed for reproducibility\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, train_dataloader, test_dataloader, epochs=2, evaluation=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28500815f96941b4917ced65cd1f511a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "703607fec0a144488f84b63e2ae16778",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "   1    |   18    |   0.637458   |     -      |     -     |   6.44   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.637458   |  0.345500  |   95.83   |   6.68   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   18    |   0.270310   |     -      |     -     |   6.26   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.270310   |  0.202803  |   93.75   |   6.49   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5ostg9kPlra"
      },
      "source": [
        "### 3.4. Evaluation on Validation Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIlSTDA7Z9DF"
      },
      "source": [
        " 예측 단계에서 softmax layer로 통과시켜 긍/부정의 확률값을 계산한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5_w4erqGzpe"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        all_logits.append(logits)\n",
        "    \n",
        "    # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "\n",
        "    # Apply softmax to calculate probabilities\n",
        "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcmj5s0eRMUh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "2c7ad099-0411-483c-8b27-b4582be10356"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Evaluate the Bert classifier\n",
        "evaluate_roc(probs, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.9773\n",
            "Accuracy: 90.91%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5wV5fXH8c8BaSKigjFKkygqRXpAbNhQRBANimgsKIrGrmhEjT9LTIzRGEuwYMMKURIRK0QBEZXeqyIoRVFEVJAiC+f3xzPrXtbdu5fdvXW/79frvnbmztyZc2d377nPPDPnMXdHRESkOJXSHYCIiGQ2JQoREYlLiUJEROJSohARkbiUKEREJC4lChERiUuJQnaImc0zs6PSHUemMLObzOyJNO17iJndmY59lzcz+72ZjS7la/U3mWRKFFnMzD4zs41mtt7MVkUfHLskc5/u3tzdxyVzH/nMrJqZ3WVmy6L3+YmZXW9mlor9FxHPUWa2IvY5d/+ru1+YpP2ZmV1pZnPN7EczW2FmL5vZwcnYX2mZ2W1m9nxZtuHuL7j78Qns6xfJMZV/kxWVEkX26+HuuwCtgTbAjWmOZ4eZ2U7FLHoZOBboBtQCzgH6Aw8kIQYzs0z7f3gAuAq4EtgDOAAYAZxU3juK8ztIunTuWxLk7npk6QP4DDguZv7vwBsx84cAHwLfAbOAo2KW7QE8DXwBrAVGxCzrDsyMXvch0LLwPoF9gI3AHjHL2gDfAFWi+QuABdH2RwGNYtZ14DLgE2BpEe/tWGAT0KDQ8x2BrcD+0fw44C5gMvAD8GqhmOIdg3HAX4APoveyP3B+FPM6YAlwcbRuzWidbcD66LEPcBvwfLTOvtH7Og9YFh2Lm2P2VwN4JjoeC4A/AiuK+d02id5nhzi//yHAIOCNKN5JwH4xyx8AlkfHZRpwRMyy24DhwPPR8guBDsBH0bH6EvgXUDXmNc2B/wHfAl8BNwFdgZ+ALdExmRWtWxt4MtrOSuBOoHK0rG90zP8JrImW9QUmRMstWvZ1FNscoAXhS8KWaH/rgdcK/x8AlaO4Po2OyTQK/Q3pUYrPmnQHoEcZfnnb/4PUj/6hHojm60X/hN0ILccu0fye0fI3gH8DuwNVgM7R822if9CO0T/dedF+qhWxzzHARTHx3AM8Gk33BBYDTYGdgD8BH8as69GHzh5AjSLe29+A94p5359T8AE+LvogakH4MP8PBR/cJR2DcYQP9OZRjFUI39b3iz6sOgMbgLbR+kdR6IOdohPF44Sk0ArYDDSNfU/RMa8PzC68vZjtXgJ8XsLvf0j0fjpE8b8ADItZfjZQJ1o2AFgFVI+JewtwSnRsagDtCIl1p+i9LACujtavRfjQHwBUj+Y7Fj4GMft+BXgs+p38ipDI839nfYE84IpoXzXYPlGcQPiA3y36PTQF9o55z3fG+T+4nvB/cGD02lZAnXT/r2b7I+0B6FGGX174B1lP+ObkwLvAbtGyG4DnCq0/ivDBvzfhm/HuRWzzEeDPhZ5bREEiif2nvBAYE00b4dvrkdH8W0C/mG1UInzoNormHTgmznt7IvZDr9CyiUTf1Akf9n+LWdaM8I2zcrxjEPPaO0o4xiOAq6Lpo0gsUdSPWT4Z6BNNLwFOiFl2YeHtxSy7GZhYQmxDgCdi5rsBC+OsvxZoFRP3+BK2fzXwSjR9JjCjmPV+PgbR/F6EBFkj5rkzgbHRdF9gWaFt9KUgURwDfExIWpWKeM/xEsUioGcy/t8q8iPTzsnKjjvF3WsRPsQOAupGzzcCTjez7/IfwOGEJNEA+Nbd1xaxvUbAgEKva0A4zVLYf4BOZrY3cCQh+bwfs50HYrbxLSGZ1It5/fI47+ubKNai7B0tL2o7nxNaBnWJfwyKjMHMTjSziWb2bbR+NwqOaaJWxUxvAPIvMNin0P7ivf81FP/+E9kXZnadmS0ws++j91Kb7d9L4fd+gJm9Hl0Y8QPw15j1GxBO5ySiEeF38GXMcX+M0LIoct+x3H0M4bTXIOBrMxtsZrsmuO8diVMSpESRI9z9PcK3rXujp5YTvk3vFvOo6e5/i5btYWa7FbGp5cBfCr1uZ3cfWsQ+1wKjgTOAswgtAI/ZzsWFtlPD3T+M3USct/QO0NHMGsQ+aWYdCR8GY2Kejl2nIeGUyjclHINfxGBm1QjJ715gL3ffDXiTkOBKijcRXxJOORUVd2HvAvXNrH1pdmRmRxD6QHoTWo67Ad9T8F7gl+/nEWAh0MTddyWc689ffznwm2J2V3g7ywktiroxx31Xd28e5zXbb9D9QXdvR2ghHkA4pVTi66J971fCOrKDlChyy/1AFzNrReik7GFmJ5hZZTOrHl3eWd/dvyScGnrYzHY3sypmdmS0jceBS8ysY3QlUE0zO8nMahWzzxeBc4HToul8jwI3mllzADOrbWanJ/pG3P0dwoflf8ysefQeDone1yPu/knM6mebWTMz2xm4Axju7lvjHYNidlsVqAasBvLM7EQg9pLNr4A6ZlY70fdRyEuEY7K7mdUDLi9uxej9PQwMjWKuGsXfx8wGJrCvWoR+gNXATmb2f0BJ38prETqP15vZQcAfYpa9DuxtZldHly3XipI2hOOyb/5VY9Hf12jgH2a2q5lVMrP9zKxzAnFjZr+N/v6qAD8SLmrYFrOv4hIWhFOWfzazJtHfb0szq5PIfqV4ShQ5xN1XA88C/+fuywkdyjcRPiyWE76V5f/OzyF8815I6Ly+OtrGVOAiQtN/LaFDum+c3Y4kXKGzyt1nxcTyCnA3MCw6jTEXOHEH31IvYCzwNqEv5nnClTRXFFrvOUJrahWho/XKKIaSjsF23H1d9NqXCO/9rOj95S9fCAwFlkSnVIo6HRfPHcAKYCmhxTSc8M27OFdScArmO8IplVOB1xLY1yjCcfuYcDpuE/FPdQFcR3jP6whfGP6dvyA6Nl2AHoTj/AlwdLT45ejnGjObHk2fS0i88wnHcjiJnUqDkNAej173OeE03D3RsieBZtHxH1HEa+8j/P5GE5Lek4TOcikDKzhTIJJ9zGwcoSM1LXdHl4WZ/YHQ0Z3QN22RdFGLQiRFzGxvMzssOhVzIOFS01fSHZdISZKWKMzsKTP72szmFrPczOxBM1tsZrPNrG2yYhHJEFUJV/+sI3TGv0rohxDJaEk79RR1jq4HnnX3FkUs70Y419yNcHPXA+7esfB6IiKSXklrUbj7eMK188XpSUgi7u4Tgd2i6/FFRCSDpLMYVz22vwpjRfTcl4VXNLP+hDov1KxZs91BBx2UkgDLy6JFsHEj1NC1FyKSYntt/pxd8r5jlud94+57lmYbWVG10d0HA4MB2rdv71OnTk1zRDvmqKPCz3Hj0hmFiFQY+V0KZvDII/D119htt31e2s2l86qnlWx/Z2r96DkRESmtlSuhZ094Mbr/9Q9/gFtvLdMm05koRgLnRlc/HQJ8H93RKSIiO8odHn8cmjWDd96B9evLbdNJO/VkZkMJherqWhgV7FZCoTDc/VFCDZ1uhDt/NxDGARARkR316adw0UUwdiwcfXRIGPuVX8mrpCUKdz+zhOX5A9eIiEhZzJkD06bB4MFw4YWhb6IcZUVntoiIFDJ3LkyfDueeC6ecAkuWQJ3k1D9UCQ8RkWzy009w223Qti3cfDNs2hSeT1KSACUKEZHsMWlSSBC33w5nnAEzZkD16knfrU49iYhkg5Ur4YgjYK+94PXX4aSTUrZrtShERDLZxx+Hn/Xqwb//DfPmpTRJgBKFiEhm+u476N8fDjoIxo8Pz516Kuya6PDh5UennkREMs3IkeGO6lWr4Prr4be/TWs4ShQiIpnkwgvhySfh4IPh1Vehfft0R6REISKSdrFF/Nq3h0aN4IYboGrV9MYVUaIQEUmn5cvhkkugTx8455wwnWHUmS0ikg7btoUS4M2bhzEINm9Od0TFUotCRCTVPvkk9EWMHw/HHRdqNDVunO6oiqVEISKSavPnw+zZ8NRT0LdvuRfxK29KFCIiqTBrFsycCeedFwYWWrIEdt893VElRH0UIiLJtHkz3HJLuJrpllsKivhlSZIAJQoRkeT56CNo0wbuvBPOOitlRfzKm049iYgkw8qV0Lkz/PrX8OabcOKJ6Y6o1NSiEBEpTwsWhJ/16sFLL4UiflmcJEAtioQNHgwvvli6186cCa1bl288IpJh1q6FAQPg6afDZa9HHBFGnssBalEk6MUXwwd+abRuHU5PikiOeuUVaNYMnn0Wbrwx7UX8yptaFDugdetwA6WIyM8uuCC0Ilq3hjfeCCPQ5RglChGRHRVbxO+QQ6BJE7juOqhSJb1xJYkShYjIjvj8c7j44nA++dxzw+BCOU59FCIiidi2DQYNghYtYMIE2LIl3RGljFoUIiIlWbQoFPGbMAGOPx4eewz23TfdUaWMEoWISEkWLQr3QwwZEk43ZXgRv/KmRCEiUpQZM8I18eefDyefHIr47bZbuqNKC/VRiIjE2rQJbrop3Atx220FRfwqaJKACtSiKMud1aC7q0UqhA8+gH79wqmm88+Hf/wjK4v4lbcK06Ioy53VoLurRXLeypVw9NGhLPioUWFQoSwqBZ5MFaZFAbqzWkSKMH9+KL9Rrx785z8hWeyyS7qjyigVpkUhIrKdb78Nw5A2bx6K+AH06KEkUYQK1aIQEQFCy+Gyy2DNGrj5ZujQId0RZTQlChGpWPr2hWeeCcX73n5bV6kkQIlCRHJfbBG/Qw+Fpk3D2BE76SMwEUntozCzrma2yMwWm9nAIpY3NLOxZjbDzGabWbdkxiMiFdDSpaHsxrPPhvn+/eGGG5QkdkDSEoWZVQYGAScCzYAzzaxZodX+BLzk7m2APsDDyYpHRCqYrVvhwQdDEb+JEwtaFbLDktmi6AAsdvcl7v4TMAzoWWgdB3aNpmsDXyQxHhGpKBYsCEORXnUVdO4c6jT17ZvuqLJWMtte9YDlMfMrgI6F1rkNGG1mVwA1geOK2pCZ9Qf6AzRs2LDcAxWRHLN4cbi7+rnn4Pe/r3BF/Mpbuu+jOBMY4u71gW7Ac2b2i5jcfbC7t3f39nvuuWfKgxSRLDBtWribGsL9EEuXwtlnK0mUg2QmipVAg5j5+tFzsfoBLwG4+0dAdaBuEmMSkVyzcSMMHAgdO8Kf/1xQxG/XXeO/ThKWzEQxBWhiZo3NrCqhs3pkoXWWAccCmFlTQqJYncSYRCSXjB8PrVrB3XeHPogZM1TELwmS1kfh7nlmdjkwCqgMPOXu88zsDmCqu48EBgCPm9k1hI7tvu66NEFEErByJRx7LDRoAO+8E6YlKSzbPpdr1Wrv7dpN3eHX5ZcJV1FAkSw3Zw4cfHCYfv31UMSvZs30xpQFzGyau7cvzWvT3Zm9wzZuLN3rVCZcJMt98w2ccw60bFlQxK97dyWJFMi6WxNr1FCrQKRCcYeXX4bLL4e1a+HWW0PHtaRM1iUKEalgzjsv3A/Rvj28+27BaSdJGSUKEck8sUX8OncOp5uuvlr1mdIk6/ooRCTHLVkCxx0HQ4aE+X794LrrlCTSSIlCRDLD1q1w//3h1NKUKVBJH0+ZQilaRNJv/ny44AKYNAlOOgkefRTq1093VBJRohCR9Fu6FD79FF58Efr0UX2mDKNEISLpMWVKuBP2ootCK2LJEqhVK91RSRF0ElBEUmvDhtA5fcghcNddBUX8lCQylhKFiKTOuHHhUtd//CO0JFTELyvo1JOIpMaKFdClCzRqBGPGhBpNkhXUohCR5Jo1K/ysXx9efRVmz1aSyDJKFCKSHKtXh0qcrVvDe++F57p1g513Tm9cssN06klEypc7DBsGV14J338Pt98OnTqlOyopAyUKESlf55wDL7wQKrw++SQ0b57uiKSMEk4UZrazu29IZjAikqW2bQs3yZmF/od27UKLonLldEcm5aDEPgozO9TM5gMLo/lWZvZw0iMTkeyweHEYhvTpp8N8v35wzTVKEjkkkc7sfwInAGsA3H0WcGQygxKRLJCXB/feG4r4zZgBVaumOyJJkoROPbn7ctu+9srW5IQjIllh7lw4/3yYOhV69oSHH4Z99kl3VJIkiSSK5WZ2KOBmVgW4CliQ3LBEJKMtWwaffx6uburdW0X8clwiieIS4AGgHrASGA1cmsygRCQDTZoUbp7r3z/cD7FkCeyyS7qjkhRIpI/iQHf/vbvv5e6/cvezgabJDkxEMsSPP8K114Z7If7+d9i8OTyvJFFhJJIoHkrwORHJNWPGhCJ+//wnXHIJTJ8O1aqlOypJsWJPPZlZJ+BQYE8zuzZm0a6ArnsTyXUrVsAJJ0DjxqEEx5G62LGiitdHURXYJVontlD8D8BpyQxKRNJoxgxo0yYU8XvtNejcGWrUSHdUkkbm7vFXMGvk7p+nKJ4S1arV3tetm5ruMERyz1dfhbupX3opjBvRuXO6I5JyZGbT3L19aV6byFVPG8zsHqA58PMII+5+TGl2KCIZxj3UZrrqKli/Hu68Ew49NN1RSQZJpDP7BUL5jsbA7cBnwJQkxiQiqXTWWaGQ34EHhjGsb74ZqlRJd1SSQRJpUdRx9yfN7Cp3fw94z8yUKESyWWwRv+OPD5e+XnaZ6jNJkRJpUWyJfn5pZieZWRtgjyTGJCLJ9PHHocLrU0+F+fPPV6VXiSuRFsWdZlYbGEC4f2JX4OqkRiUi5S8vD+67D269FapX15VMkrASE4W7vx5Nfg8cDWBmhyUzKBEpZ7NnwwUXwLRpcOqpMGgQ7L13uqOSLBHvhrvKQG9Cjae33X2umXUHbgJqAG1SE6KIlNmKFbB8Obz8MvTqpSJ+skPi9VE8CVwI1AEeNLPngXuBv7t7QknCzLqa2SIzW2xmA4tZp7eZzTezeWb24o6+AREpxocfwqOPhun8In6nnaYkITss3qmn9kBLd99mZtWBVcB+7r4mkQ1HLZJBQBdgBTDFzEa6+/yYdZoANwKHuftaM/tVad+IiETWrw+XuD70EOy3X+isrlYNatZMd2SSpeK1KH5y920A7r4JWJJokoh0ABa7+xJ3/wkYBvQstM5FwCB3Xxvt5+sd2L6IFDZ6NLRoEZLEZZepiJ+Ui3gtioPMbHY0bcB+0bwB7u4tS9h2PWB5zPwKoGOhdQ4AMLMPCIUGb3P3twtvyMz6A/0BqlUrabciFdTy5XDSSaEVMX48HH54uiOSHBEvUaRizImdgCbAUUB9YLyZHezu38Wu5O6DgcEQaj2lIC6R7DFtGrRrBw0awJtvwhFHhMtfRcpJsaee3P3zeI8Etr0SaBAzXz96LtYKYKS7b3H3pcDHhMQhIiVZtQpOPx3atw9lwAG6dFGSkHKXyJ3ZpTUFaGJmjc2sKtAHGFlonRGE1gRmVpdwKmpJEmMSyX7u8Mwz0KxZKAP+17+qiJ8kVSJ3ZpeKu+eZ2eXAKEL/w1PuPs/M7gCmuvvIaNnxZjYf2Apcv4Md5iIVT58+oRT4YYfBE0/AQQelOyLJcSWORwFgZjWAhu6+KPkhxafxKKRCii3i98wzsG4dXHopVErmSQHJJWUZj6LEvzIz6wHMBN6O5lubWeFTSCKSLAsXhmFIn3wyzJ93Hlx+uZKEpEwif2m3Ee6J+A7A3WcSxqYQkWTasiX0P7RqBfPnwy67pDsiqaAS6aPY4u7f2/a3/esSVZFkmjkz3FE9c2You/HQQ/DrX6c7KqmgEkkU88zsLKByVHLjSuDD5IYlUsGtWhUe//kP/O536Y5GKrhETj1dQRgvezPwIqHcuMajEClvEybAww+H6a5d4dNPlSQkI5R41ZOZtXX36SmKp0S66klyzrp1cOONYYyIJk1gzhzVZ5Jyl9SrnoB/mNkCM/uzmbUozU5EpBijRoUifg8/DFddpSJ+kpFKTBTufjRhZLvVwGNmNsfM/pT0yERy3fLl0L077LxzOO10//26skkyUkIXYrv7Knd/ELiEcE/F/yU1KpFc5Q6TJ4fpBg3grbdgxgyV4JCMlsgNd03N7DYzmwM8RLjiqX7SIxPJNV9+GYYh7dixoIjfccepiJ9kvEQuj30K+Ddwgrt/keR4RHKPOwwZAtdeC5s2wd13hzpNIlmixETh7p1SEYhIzurdG4YPD+NEPPEEHHBAuiMS2SHFJgoze8nde0ennGKvoU10hDuRimvr1lDAr1Il6NEDjjkGLr5Y9ZkkK8VrUVwV/eyeikBEcsaCBdCvXyjBcdFFcO656Y5IpEzijXD3ZTR5aRGj212amvBEssiWLXDnndC6NSxaBLVrpzsikXKRSDu4SxHPnVjegYhktRkzwpCkt9wCp54aWhW9e6c7KpFyEa+P4g+ElsNvzGx2zKJawAfJDkwkq3z1FXzzDYwYAT17pjsakXJVbK0nM6sN7A7cBQyMWbTO3b9NQWxFUq0nyRjjx4e6TJddFuY3boQaNdIbk0gxklXryd39M+AyYF3MAzPbozQ7E8kJP/wQhiHt3BkefBA2bw7PK0lIjop31dOLhCuephEuj40duciB3yQxLpHM9Oab4TLXL74IN9DdcYeK+EnOKzZRuHv36KeGPRWBUMSvZ0848MBwA13HjumOSCQlEqn1dJiZ1Yymzzaz+8ysYfJDE8kA7jBxYphu0ABGjw6lwJUkpAJJ5PLYR4ANZtYKGAB8CjyX1KhEMsEXX8App0CnTgVF/I4+GqpWTW9cIimWSKLI83BpVE/gX+4+iHCJrEhucg81mZo1Cy2Ie+9VET+p0BKpHrvOzG4EzgGOMLNKQJXkhiWSRqedBv/9b7iq6YknYP/90x2RSFol0qI4A9gMXODuqwhjUdyT1KhEUm3rVti2LUyfcgo8+iiMGaMkIUKcG+62W8lsL+C30exkd/86qVHFoRvupNzNnQsXXhgK+V10UbqjEUmKZN1wl7/x3sBk4HSgNzDJzE4rzc5EMspPP8Htt0PbtvDpp7D77umOSCQjJdJHcTPw2/xWhJntCbwDDE9mYCJJNW0a9O0bWhNnnQX33w977pnuqEQyUiKJolKhU01rSKxvQyRzrVkD330Hr70G3TXkikg8iSSKt81sFDA0mj8DeDN5IYkkydixoYjflVfC8cfDJ59A9erpjkok45XYMnD364HHgJbRY7C735DswETKzfffh/pMxxwDjzxSUMRPSUIkIfHGo2gC3AvsB8wBrnP3lakKTKRcvPYaXHIJrFoF110XOq9VxE9kh8RrUTwFvA70IlSQfSglEYmUl+XLoVcvqFMn1Gu65x7Yeed0RyWSdeL1UdRy98ej6UVmNj0VAYmUiTt89BEcemhBEb9DD1V9JpEyiNeiqG5mbcysrZm1BWoUmi+RmXU1s0VmttjMBsZZr5eZuZmV6mYQEQBWrICTTw51mfKL+B11lJKESBnFa1F8CdwXM78qZt6BY+Jt2MwqA4OALsAKYIqZjXT3+YXWqwVcBUzasdBFItu2weOPw/XXQ14e3HcfHH54uqMSyRnxBi46uozb7gAsdvclAGY2jFCBdn6h9f4M3A1cX8b9SUXVqxeMGBGuanr8cfiNBl8UKU/JvHGuHrA8Zn5F9NzPolNYDdz9jXgbMrP+ZjbVzKZu2bKl/COV7JOXV1DEr1evkCDeeUdJQiQJ0naHdVSu/D7CYEhxuftgd2/v7u2rVFGF8wpv9uwwmNDj0bUWZ58divqZxX+diJRKMhPFSqBBzHz96Ll8tYAWwDgz+ww4BBipDm0p1ubNcOut0K4dfP65ajOJpEgi1WMtGiv7/6L5hmbWIYFtTwGamFljM6sK9AFG5i909+/dva677+vu+wITgZPdXTXE5ZemTAlVXu+4A848ExYsgN/9Lt1RiVQIibQoHgY6AWdG8+sIVzPF5e55wOXAKGAB8JK7zzOzO8zs5FLGKxXV2rWwfj28+SY8+2y4iU5EUqLEgYvMbLq7tzWzGe7eJnpulru3SkmEhWjgogpkzJhQxO+qq8L85s0qvyFSSkkduAjYEt0T4dHO9gS2lWZnIgn57rsw0tyxx8JjjxUU8VOSEEmLRBLFg8ArwK/M7C/ABOCvSY1KKq5XX4VmzeCpp+CPfwwDDClBiKRVieNRuPsLZjYNOBYw4BR3X5D0yKTiWbYMTj8dmjaFkSOhvS6AE8kEJSYKM2sIbABei33O3ZclMzCpINxhwgQ44gho2DDcNHfIIarPJJJBEhnh7g1C/4QB1YHGwCKgeRLjkopg2bIwVsRbb8G4cdC5Mxx5ZLqjEpFCEjn1dHDsfFR249KkRSS5b9s2ePRRuOGG0KJ48EEV8RPJYIm0KLbj7tPNrGMygpEK4ne/C53WXbrA4MGw777pjkhE4kikj+LamNlKQFvgi6RFJLkpLw8qVQqPM86Anj2hb1/VZxLJAolcHlsr5lGN0GfRM5lBSY6ZNQs6dgytBwglOM4/X0lCJEvEbVFEN9rVcvfrUhSP5JJNm+DOO+Huu2GPPeDXv053RCJSCsUmCjPbyd3zzOywVAYkOWLyZDjvPFi4MPy8776QLEQk68RrUUwm9EfMNLORwMvAj/kL3f2/SY5NstkPP8DGjfD223DCCemORkTKIJGrnqoDawhjZOffT+GAEoVsb/RomDcPrrkGjjsOFi1S+Q2RHBAvUfwquuJpLgUJIl/8krNSsaxdC9deC0OGQPPmcOmlIUEoSYjkhHhXPVUGdoketWKm8x8i8N//hiJ+zz0HN94IU6cqQYjkmHgtii/d/Y6URSLZZ9ky6NMHWrQIAwq1aZPuiEQkCeK1KHSRu/ySO7z3Xphu2DAMLjRpkpKESA6LlyiOTVkUkh0+/xxOPBGOOqogWRx+OFSpktawRCS5ik0U7v5tKgORDLZtG/zrX6GjesIEeOihUBZcRCqEHS4KKBXQKafAa6+F+yEeewwaNUp3RCKSQkoUUrQtW6By5VDE78wz4bTT4JxzVJ9JpAJKpCigVDTTp0OHDmHMCAiJ4txzlSREKiglCimwcWO4F6JDB1i1Cho0SHdEIpIBdOpJgokTQ/G+jz+GCy6Ae++F3XdPd1QikgGUKCT48cfQL/G//4U6TSIiESWKiuztt0MRvwED4NhjQ0nwqlXTHZWIZBj1UVREa9aE00wnngjPPBPmy/sAABJMSURBVAM//RSeV5IQkSIoUVQk7jB8eCji9+KL8Kc/wZQpShAiEpdOPVUky5bBWWdBy5Zh7IhWrdIdkYhkAbUocp17KNwH4Y7qcePCFU5KEiKSICWKXLZ0KRx/fOiozi/id+ihsJMakiKSOCWKXLR1KzzwQBgnYtIkeOQRFfETkVLTV8tc1LMnvPEGdOsWynDoDmsRKQMlilwRW8TvnHNCfaazzlJ9JhEps6SeejKzrma2yMwWm9nAIpZfa2bzzWy2mb1rZqpfXRpTp0L79uEUE8AZZ8Dvf68kISLlImmJwswqA4OAE4FmwJlm1qzQajOA9u7eEhgO/D1Z8eSkjRvhhhugY0dYvVrjRIhIUiSzRdEBWOzuS9z9J2AY0DN2BXcf6+4botmJQP0kxpNbPvooXOL697+HIn7z50P37umOSkRyUDL7KOoBy2PmVwAd46zfD3irqAVm1h/oD1CtWsvyii+7bdwYhih9551w+auISJJkRGe2mZ0NtAc6F7Xc3QcDgwFq1WrvKQwts7z5Zijid/31cMwxsGABVKmS7qhEJMcl89TTSiD2usz60XPbMbPjgJuBk919cxLjyV7ffANnnw0nnQQvvFBQxE9JQkRSIJmJYgrQxMwam1lVoA8wMnYFM2sDPEZIEl8nMZbs5A7DhkHTpvDSS3DrrTB5sor4iUhKJe3Uk7vnmdnlwCigMvCUu88zszuAqe4+ErgH2AV42cKlnMvc/eRkxZR1li0L5cBbtYInn4SDD053RCJSAZl7dp3yr1Wrva9bNzXdYSSPO7z7bsEocxMnwm9/G26mExEpJTOb5u7tS/Na1XrKJJ9+Gq5g6tKloIjfIYcoSYhIWilRZIKtW+G++8KppWnT4LHHVMRPRDJGRlweW+H16AFvvRVumHvkEaiv+w5FJHMoUaTLTz+FcSEqVYK+fUMhvz59VJ9JRDKOTj2lw+TJ0K4dPPxwmO/dO1R7VZIQkQykRJFKGzbAgAHQqROsXQv77ZfuiERESqRTT6kyYUK4J2LJErj4Yrj7bqhdO91RiYiUSIkiVfIHFho7Fo46Kt3RiIgkTIkimV57LRTu++Mf4eijQynwnXTIRSS7qI8iGVavDsOQnnwyDB1aUMRPSUJEspASRXlyhxdfDEX8hg+HO+6ASZNUxE9Espq+4panZcvg/POhTZtQxK9583RHJCJSZmpRlNW2bTBqVJhu1Ajefx8++EBJQkRyhhJFWXzySRhprmtXGD8+PNehg4r4iUhOUaIojbw8uOceaNkSZs4Mp5lUxE9EcpT6KEqje/dwuqlnz1CGY5990h2RSEbasmULK1asYNOmTekOpcKoXr069evXp0o5DpWsgYsStXlzGKO6UqVwRdO2bXD66arPJBLH0qVLqVWrFnXq1MH0v5J07s6aNWtYt24djRs33m6ZBi5KtokToW1bGDQozJ92Wijkpz98kbg2bdqkJJFCZkadOnXKvQWnRBHPjz/CNdfAoYfCunXQpEm6IxLJOkoSqZWM460+iuK8/34o4rd0KVx6Kdx1F+y6a7qjEhFJObUoipOXF/ok3nsvnHJSkhDJWiNGjMDMWLhw4c/PjRs3ju7du2+3Xt++fRk+fDgQOuIHDhxIkyZNaNu2LZ06deKtt94qcyx33XUX+++/PwceeCCj8u/BKmTMmDG0bduWFi1acN5555GXlwfA999/T48ePWjVqhXNmzfn6aefLnM8iVCiiDViRGg5QCjiN28eHHlkemMSkTIbOnQohx9+OEOHDk34Nbfccgtffvklc+fOZfr06YwYMYJ169aVKY758+czbNgw5s2bx9tvv82ll17K1q1bt1tn27ZtnHfeeQwbNoy5c+fSqFEjnnnmGQAGDRpEs2bNmDVrFuPGjWPAgAH8lF9LLol06gngq6/giivg5ZdDp/WAAaE+k4r4iZSbq68Otx2Vp9at4f7746+zfv16JkyYwNixY+nRowe33357idvdsGEDjz/+OEuXLqVatWoA7LXXXvTu3btM8b766qv06dOHatWq0bhxY/bff38mT55Mp06dfl5nzZo1VK1alQMOOACALl26cNddd9GvXz/MjHXr1uHurF+/nj322IOdUvA5VbFbFO7w3HPQrBm8+ir85S/hCicV8RPJGa+++ipdu3blgAMOoE6dOkybNq3E1yxevJiGDRuyawKnnK+55hpat279i8ff/va3X6y7cuVKGjRo8PN8/fr1Wbly5Xbr1K1bl7y8PKZODbcBDB8+nOXLlwNw+eWXs2DBAvbZZx8OPvhgHnjgASpVSv7HeMX+yrxsGVx4IbRvH+6uPuigdEckkrNK+uafLEOHDuWqq64CoE+fPgwdOpR27doVe3XQjl419M9//rPMMRbe/7Bhw7jmmmvYvHkzxx9/PJWjskCjRo2idevWjBkzhk8//ZQuXbpwxBFHJJTQyqLiJYr8In4nnhiK+H3wQaj2qvpMIjnn22+/ZcyYMcyZMwczY+vWrZgZ99xzD3Xq1GHt2rW/WL9u3brsv//+LFu2jB9++KHED+FrrrmGsWPH/uL5Pn36MHDgwO2eq1ev3s+tA4AVK1ZQr169X7y2U6dOvP/++wCMHj2ajz/+GICnn36agQMHYmbsv//+NG7cmIULF9KhQ4fEDkhpuXtWPXbZpZ2X2qJF7kcc4Q7u48aVfjsikpD58+endf+PPfaY9+/ff7vnjjzySH/vvfd806ZNvu+++/4c42effeYNGzb07777zt3dr7/+eu/bt69v3rzZ3d2//vprf+mll8oUz9y5c71ly5a+adMmX7JkiTdu3Njz8vJ+sd5XX33l7u6bNm3yY445xt999113d7/kkkv81ltvdXf3VatW+T777OOrV6/+xeuLOu7AVC/l527F6KPIy4O77w5F/ObMgaef1tVMIhXA0KFDOfXUU7d7rlevXgwdOpRq1arx/PPPc/7559O6dWtOO+00nnjiCWrXrg3AnXfeyZ577kmzZs1o0aIF3bt3L/MpnubNm9O7d2+aNWtG165dGTRo0M+nlbp168YXX3wBwD333EPTpk1p2bIlPXr04JhjjgHClVgffvghBx98MMceeyx33303devWLVNMiagYtZ5OOAFGj4bf/S7cE/HrXycnOBHZzoIFC2jatGm6w6hwijruZan1lLt9FJs2hRvmKleG/v3Do1evdEclIpJ1cvPU0wcfhAus84v49eqlJCEiUkq5lSjWr4crrwyDCG3aBGryiqRdtp3eznbJON65kyjeew9atIB//QsuvxzmzoUuXdIdlUiFVr16ddasWaNkkSIejUdRvXr1ct1ubvVR7LxzqPp62GHpjkRECHcer1ixgtWrV6c7lAojf4S78pTdVz3997+wcCHcdFOY37pVN86JiBQhY0e4M7OuZrbIzBab2cAillczs39HyyeZ2b4JbXjVqjDKXK9e8MorkF89UUlCRKTcJS1RmFllYBBwItAMONPMmhVarR+w1t33B/4J3F3SdmtvWRM6qV9/PZQE//BDFfETEUmiZLYoOgCL3X2Ju/8EDAN6FlqnJ/BMND0cONZKqMi11+bPQ6f1rFkwcGC4V0JERJImmZ3Z9YDlMfMrgI7FrePueWb2PVAH+CZ2JTPrD/SPZjfbhAlzVekVgLoUOlYVmI5FAR2LAjoWBQ4s7Quz4qondx8MDAYws6ml7ZDJNToWBXQsCuhYFNCxKGBmO1j7qEAyTz2tBBrEzNePnityHTPbCagNrEliTCIisoOSmSimAE3MrLGZVQX6ACMLrTMSOC+aPg0Y49l2va6ISI5L2qmnqM/hcmAUUBl4yt3nmdkdhLroI4EngefMbDHwLSGZlGRwsmLOQjoWBXQsCuhYFNCxKFDqY5F1N9yJiEhq5U6tJxERSQolChERiStjE0XSyn9koQSOxbVmNt/MZpvZu2bWKB1xpkJJxyJmvV5m5maWs5dGJnIszKx39Lcxz8xeTHWMqZLA/0hDMxtrZjOi/5Nu6Ygz2czsKTP72szmFrPczOzB6DjNNrO2CW24tINtJ/NB6Pz+FPgNUBWYBTQrtM6lwKPRdB/g3+mOO43H4mhg52j6DxX5WETr1QLGAxOB9umOO41/F02AGcDu0fyv0h13Go/FYOAP0XQz4LN0x52kY3Ek0BaYW8zybsBbgAGHAJMS2W6mtiiSUv4jS5V4LNx9rLtviGYnEu5ZyUWJ/F0A/JlQN2xTKoNLsUSOxUXAIHdfC+DuX6c4xlRJ5Fg4sGs0XRv4IoXxpYy7jydcQVqcnsCzHkwEdjOzvUvabqYmiqLKf9Qrbh13zwPyy3/kmkSORax+hG8MuajEYxE1pRu4+xupDCwNEvm7OAA4wMw+MLOJZtY1ZdGlViLH4jbgbDNbAbwJXJGa0DLOjn6eAFlSwkMSY2ZnA+2BzumOJR3MrBJwH9A3zaFkip0Ip5+OIrQyx5vZwe7+XVqjSo8zgSHu/g8z60S4f6uFu29Ld2DZIFNbFCr/USCRY4GZHQfcDJzs7ptTFFuqlXQsagEtgHFm9hnhHOzIHO3QTuTvYgUw0t23uPtS4GNC4sg1iRyLfsBLAO7+EVCdUDCwokno86SwTE0UKv9RoMRjYWZtgMcISSJXz0NDCcfC3b9397ruvq+770vorznZ3UtdDC2DJfI/MoLQmsDM6hJORS1JZZApksixWAYcC2BmTQmJoiKOzzoSODe6+ukQ4Ht3/7KkF2XkqSdPXvmPrJPgsbgH2AV4OerPX+buJ6ct6CRJ8FhUCAkei1HA8WY2H9gKXO/uOdfqTvBYDAAeN7NrCB3bfXPxi6WZDSV8Oagb9cfcClQBcPdHCf0z3YDFwAbg/IS2m4PHSkREylGmnnoSEZEMoUQhIiJxKVGIiEhcShQiIhKXEoWIiMSlRCEZycy2mtnMmMe+cdZdXw77G2JmS6N9TY/u3t3RbTxhZs2i6ZsKLfuwrDFG28k/LnPN7DUz262E9VvnaqVUSR1dHisZyczWu/su5b1unG0MAV539+Fmdjxwr7u3LMP2yhxTSds1s2eAj939L3HW70uooHt5ecciFYdaFJIVzGyXaKyN6WY2x8x+UTXWzPY2s/Ex37iPiJ4/3sw+il77spmV9AE+Htg/eu210bbmmtnV0XM1zewNM5sVPX9G9Pw4M2tvZn8DakRxvBAtWx/9HGZmJ8XEPMTMTjOzymZ2j5lNicYJuDiBw/IRUUE3M+sQvccZZvahmR0Y3aV8B3BGFMsZUexPmdnkaN2iqu+KbC/d9dP10KOoB+FO4pnR4xVCFYFdo2V1CXeW5reI10c/BwA3R9OVCbWf6hI++GtGz98A/F8R+xsCnBZNnw5MAtoBc4CahDvf5wFtgF7A4zGvrR39HEc0/kV+TDHr5Md4KvBMNF2VUMmzBtAf+FP0fDVgKtC4iDjXx7y/l4Gu0fyuwE7R9HHAf6LpvsC/Yl7/V+DsaHo3Qv2nmun+feuR2Y+MLOEhAmx099b5M2ZWBfirmR0JbCN8k94LWBXzminAU9G6I9x9ppl1JgxU80FU3qQq4Zt4Ue4xsz8RagD1I9QGesXdf4xi+C9wBPA28A8zu5twuur9HXhfbwEPmFk1oCsw3t03Rqe7WprZadF6tQkF/JYWen0NM5sZvf8FwP9i1n/GzJoQSlRUKWb/xwMnm9l10Xx1oGG0LZEiKVFItvg9sCfQzt23WKgOWz12BXcfHyWSk4AhZnYfsBb4n7ufmcA+rnf34fkzZnZsUSu5+8cWxr3oBtxpZu+6+x2JvAl332Rm44ATgDMIg+xAGHHsCncfVcImNrp7azPbmVDb6DLgQcJgTWPd/dSo439cMa83oJe7L0okXhFQH4Vkj9rA11GSOBr4xbjgFsYK/8rdHweeIAwJORE4zMzy+xxqmtkBCe7zfeAUM9vZzGoSThu9b2b7ABvc/XlCQcaixh3eErVsivJvQjG2/NYJhA/9P+S/xswOiPZZJA8jGl4JDLCCMvv55aL7xqy6jnAKLt8o4AqLmlcWKg+LxKVEIdniBaC9mc0BzgUWFrHOUcAsM5tB+Lb+gLuvJnxwDjWz2YTTTgclskN3n07ou5hM6LN4wt1nAAcDk6NTQLcCdxbx8sHA7PzO7EJGEwaXesfD0J0QEtt8YLqZzSWUjY/b4o9imU0YlOfvwF3Re4993VigWX5nNqHlUSWKbV40LxKXLo8VEZG41KIQEZG4lChERCQuJQoREYlLiUJEROJSohARkbiUKEREJC4lChERiev/Ae1AIpAY3mDkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XekOuD6KbS2Q"
      },
      "source": [
        "AUC값은 0.9773으로 나왔고, Accuracy는 90.91%가 나온다. 일단 수치로만 놓고 봤을때 꽤나 성능이 좋게 나온다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5DW6grRmfT-"
      },
      "source": [
        "### 3.5. Train Our Model on the Entire Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkMK5VqJJvSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa332b86-76e4-4b68-c7df-0687b7f441a7"
      },
      "source": [
        "# Concatenate the train set and the validation set\n",
        "full_train_data = torch.utils.data.ConcatDataset([train_data, test_data])\n",
        "full_train_sampler = RandomSampler(full_train_data)\n",
        "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
        "\n",
        "# Train the Bert Classifier on the entire training data\n",
        "set_seed(42)\n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, full_train_dataloader, epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.516691   |     -      |     -     |   7.10   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.179846   |     -      |     -     |   7.10   \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q89oT0n3N0m6"
      },
      "source": [
        "## 4. Predictions on Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sqk_CPwjN_W0"
      },
      "source": [
        "### 4.1. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U3K1LbDZTOU"
      },
      "source": [
        "테스트 데이터에 예측을 할 것인데, 우선 다시 테스트 데이터를 다시 불러올 것이다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaPBmrFBO-uQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8b19fb9e-e73c-4995-c82d-b3905d476d75"
      },
      "source": [
        "test_data.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>183</td>\n",
              "      <td>This review will...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>288</td>\n",
              "      <td>ANIME OF THE YEA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>54</td>\n",
              "      <td>For all the talk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>154</td>\n",
              "      <td>About  years ago...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>136</td>\n",
              "      <td>NO SPOILER HERE ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     review_id                                             review\n",
              "183        183                                This review will...\n",
              "288        288                                ANIME OF THE YEA...\n",
              "54          54                                For all the talk...\n",
              "154        154                                About  years ago...\n",
              "136        136                                NO SPOILER HERE ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzCpJBgWZYR_"
      },
      "source": [
        " `preprocessing_for_bert` 를 활용해서 테스트 데이터를 전처리 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56QTDchdOHBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89459c94-8de4-410a-9123-4b08ce8dac19"
      },
      "source": [
        "# Run `preprocessing_for_bert` on the test set\n",
        "print('Tokenizing data...')\n",
        "test_inputs, test_masks = preprocessing_for_bert(test_data.review)\n",
        "\n",
        "# Create the DataLoader for our test set\n",
        "test_dataset = TensorDataset(test_inputs, test_masks)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYv9lSXsQCZ2"
      },
      "source": [
        "### 4.2. Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsSlCGCAajmD"
      },
      "source": [
        "126개의 리뷰가 긍정으로 나왔는데(non-negative) 기준치 확률값을 0.992, 즉 99.2%가 넘는 것들만 선정을 하는 것으로 한다. default threshold인 0.5보다는 월등히 높은 수치이다. 즉, 확실히 긍정으로 판단하는 것들만 긍정으로 삼겠다는 것이다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGx8h7yXRkfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb88c530-70c3-4f87-a07b-ac68ff254695"
      },
      "source": [
        "# Compute predicted probabilities on the test set\n",
        "probs = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "# Get predictions from the probabilities\n",
        "threshold = 0.9\n",
        "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
        "\n",
        "# Number of tweets predicted non-negative\n",
        "print(\"Number of tweets predicted non-negative: \", preds.sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets predicted non-negative:  126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GMqDdsScTQb"
      },
      "source": [
        "한가지 문제가 발생헀다.... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCTfCTRfWZhe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ada62967-6a42-4483-ebec-d550c4686e6d"
      },
      "source": [
        "output = test_data[preds==1]\n",
        "positive_reviews = list(output.sample(20).review)\n",
        "positive_reviews[7]\n",
        "#생각보다 성능이 좋지는 않다... 데이터 정제를 좀더 해야 하나? 너무 글이 길어서 그런가?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'                              The Grandfather of Isekai You may have heard on the grapevine about which was the FIRST series to start the whole Isekai fantasy lore and truth be told there have been many series that try to push forward the genre of fanfiction and growing its culture at a time when there was no concrete grouping that allowed authors to run freely of ideas unimaginable And Im here to say that even if Mushoku Tensei regards itself as the pioneer of Naroukei LNs or Syosetu as its more wellknown its definitely the first to bring the wave of what has now become the oversaturated Isekai genre                  with its many genredefining tacticsnot in the easiest ways possible but through luck and persistence via Syosetu Heck even the novelist himself Rifujin no Maganote said so that Mushoku Tensei just borrows similar prospects of web novels that were popular at the time and mashes it all in one package But lets not take the high road too quick and slow down the paces as this road gets interesting down the lineIn order to understand how highly regarded Mushoku Tensei has been sought with its massive popularity a brief introduction into the world of Syosetu translated et al Lets Become a Novelist A popular online general literature depository for free Japanese web novels but mostly a place where amateur authors can publish their works without being tied up to the corporate plan with publishers and editors In fact most authors tend to post the works for hobby or fun and would develop the stories as they go ranging from a few pages to long epic novels They have a simple but effective system of rating works and providing comments and reviews and you can view recent rankings of the top works across genres and also over longer spans of time Because anyone can submit a story amateur readers can expect a wide range of stories with varying qualities from struggling amateurs to semipro and beyond and there is even a section on the site about authors who have gotten their works published and links to buy them But generally speaking if you stick with stories high the rankings youre likely to get some wellwritten material In a nutshell Shsetsuka ni Narukei or Syosetu is very much the Japanese equivalent of Wattpad Tumblr fanfiction but operating more towards the veins of YouTube in regards to the tools they give their writers and the whole potential for monetizationWith that set in mind Id like to bring the attention of the year when Isekai started to rise up from the ashes of the Syosetu community and then the anime scene in general  the year when the nowinfamous Black Sheep progenitor hit the small screena masive show now known as Sword Art Online or SAO written by Reki Kawahara Bear in mind that at the time before SAO hit the scene there were the earliest fantasy stories like Mahouka aka Irregular in Magic High School and Log Horizon that have long existed in Syosetu ever since  and  respectively but well come back to them shortly Series like The Familiar of Zero was groundbreaking for its Isekai summoning traits though it mostly stuck to being fanfiction but thats about the extent of fanfiction popularity in the anime scene in the late s For the simpleminded readerviewer that just thinks that Isekai as a genre now is a shitstorm Id like you to understand the term what was brought in the beginning of this review Naroukei essentially a term derived from Syosetu to define a certain set of power fantasy story structures Usually Male protagonists Overpowered with cheat abilities JRPGgame mechanics inhabitation of the worlds logic harems a lack of difficulty in life or the opposite that is Hikikomori or severe social withdrawal essentially a NEET Turning the clock back to SAO the one defining moment when it did when it came out in  was to show that not only the turn of growing adaptations have provided a way to make these series more sought into the mainstream the anime scene itself also contributed to the massive wave of Isekai LNs that we see today with varying opinions In an instant authors hitting big allowed for more amateur authors to copy similar aspects that defined the genres with the earliest of counterparts and along with it the growing popularity of anime adaptations of which Mahouka Log Horizon ReZero KonoSuba and many others that are constantly popping up more as the years pass byNow back to Mushoku Tensei considered as the Ultimate Syosetu fanfiction novel as per ANNs Kim Morrissy that got popular overtime while still desperately missing the anime adaptation for almost a decade that is until now All the traits of the usual Isekai tropes are pronounced here just that rather than going through The Usual Suspects cases of copying the bogstandard Rifujin no Maganote opted to piece this story in the most traditional way of an ACTUAL Isekai Think about it an unemployed yearold adult lazes at home watching sleazy content amidst a backdrop of despised fear shall he even step a foot outside of his house only to get thrown out and as the Bible proclaims in Acts consider his life worth nothing to him the NEETHikikomori structure got it The fatetwist of selfsacrifice via Truckkun the best wellknown trope lays all hands bare to the once despised human that no one cares about and in an instant he is reincarnated into a fantasy world as an infant that has just been newly born from his parents Paul Notos Greyrat and Zenith Greyrat the Reincarnation structure got it A second chance at life with a new name of Rudeus Greyrat living in a mundane fantasy world and learning as he ages a comingofage story at that which in my book is one of if not the most brillant wellstructured story structure to ever grace source materialsIf I have to take a gander of what Mushoku Tensei represents for the entire Isekai genre now is that it does not need to be the first to replicate the entire Isekai genre through its past and present contemporaries Rather it was the first to make headwaves through its own community situated in Syosetu as depicted by the boy who still retains his trauma from his previous life now faced with the prospect that the knowledge for magic skills in the fantasy world is learnt at a brisk pace that Rudeus has to earn these powers by himself the overpowered AF structure got it Enter Roxy Migurdia of the Migurd race despite being a yearold in a young childlike teenage body Being requested to help the Greyrat family in tutoring Rudeus to progress his magic powers it all seemed like the usual parental tutoring until the moment where Rudeus has to confront and overcome his past trauma that Roxy encouraged him to press on on a trip as simple as outside the Greyrat House Being the pedophilia that Rudeus was from birth and we have Paul to blame for the Acts of Deed with Zenith when in a world such as this there are NO rules to depict what is right and what is wrong its not by choice that Rudeus is compounded to be the pervert that weve all been watching his growth from the very beginning heck even with the Greyrat household maid Lilia Rudeus exhibits the same egregious behaviour That all changed within this one defining moment that sealed the popularity of Mushoku Tensei to reach the No  rating of Syosetu for years even beating out similar contemporaries like ReZero and Overlord though that result has long been overthrownIf you still dont understand what Im trying to say here is that despite the ONE persistent objection of a negative satire that is Rudeuss pedophilia behaviour that could continue to reek within the confines of this series and trigger LOTS of people Mushoku Tensei is definitely to me the Isekai of Isekais the one that did everything correctly The worldbuilding itself is quite the fascination with its hugely vast universe not to mention from the magic skills the various sword terminology styles languages and even to the locales themselves it truly is a rich world to behold of its magnificence and wonder that is Rifujin na Magonote taking into account readers feedback for muchneeded refinement of the story development in the stems of anticipation surprises and building interests that would set it apart from many a similar stories out there even if it has to incoporate the large portion of the tropes and cliches we now have seen with distaste from magic academys to adventurer guilds One interesting tidbit is that according to producer Nobuhiro Osawa Mushoku Tenseis anime was first greenlit in  and that year was stacked from the likes of ReZero and KonoSuba of which evidently proved that if SAO can win anime fans on the Isekai VRMMO space then both comtemporaries would do likewise based on the Naroukei front a worthy investment indeed that brought in some of the most reputable people along with the creation of a specialized studio Read on to find out what it isLets step back again and appreciate the vast character cast there is to face in Mushoku Tensei because every one of them is memorable in their own ways The Greyrat household that bears Paul Zenith Lilia and Rudeus under one roof Paul himself is a master swordsman someone who is able to master all the sword techniques and is once a ferocious warrior part of a party of adventurers Its there that he encountered Zenith who gave birth to Rudeus and conspicously a ladies man that got into all sorts of trouble and lustful ones at that similar to how Rudeuss old life was similarly correlative of As mentioned earlier in the review there are no rules speculating what is right or wrong but damn did Paul commit some of the grave mistakes that almost caused the family to break apart whether laid bare or hidden against the kindhearted Zenith Talk about an insult to injury and the family values that reek all the lustful pervertic instances The three girls who would soon be important figures in Rudeuss life the Goddess of Wisdom Roxy Migurdia parthuman elf best girl Sylphiette and distant noble relative Eris Boreas Greyrat Roxy is such a nice and kindhearted character though shell often try not to put herself down by being the stub that she is always trying to be patient with her teachings and not get ahead of herself Even kindly as to help Rudeus overcome his trauma shes one keeper of a girl Sylphiette on the other hand was found right where Rudeuss trauma was situated at in the fantasy world and due to her softspoken childlikeness she becomes a darling in the Greyrat household Unlike Rudeus Sylphiette pretty much has little experience in the fantasy world and constantly needs guidance from the caretaking of Zenith to Rudeuss magic powers with the facial expression of a child wanting to pair up with hisher siblings Eris though she will come off as a potential tsundere due to how messy her relative family is in handling her humanly morales and values and is one obnoxious mad dog loudspeaker of a spoiled brat Despite the Boreas Greyrats nonpersistence to train her to be like the nobles that the Greyrats are to be expected to uphold getting Rudeus to discipline her takes a real deal of effort and it isnt easy for a growing yearold to withstand a high libido of someone whos always a stuckup person yet cowers in fear at the most extreme of cases The relative of the Greyrat family the Boreas Greyrat mansionhold Despite living such the high life of nobles bear in mind that the city of Roa that they live in also permits the same nothing is right nor wrong juxtaposition Master Sauros and husbandandwife Philip and Hilda sure are as scummy as family fascists always trying to askew every opportunity to their advantage even sometimes coming down from up high to Rudeuss standpoint You can understand why even though Paul came from the same family name it was an entirely different bloodline that definitely shed some light on the internal conflict as such with labelling Paul as their cousin Even down to Ghislaine of the Dedoldia tribe a rocksolid swordswoman dubbed the Sword King and simultaneously Eriss bodyguard shes such a dutiful beastkin with a rocksolid butt The other characters of what we know so far that will play a huge part for the nd Cour HumanGod Ruijerd Superdia and many others Often disguising as the voice of dreams for the past Rudeus to inquisite in the fantasy world its words are vague yet very descriptive and easily discernable Who knows what this HumanGod has under its belt Ruijerd a demon from the Supard race that was once allied with but betrayed by the Demon God Laplace attempting to fix his reputation in a world where the Supard are regarded as fearsome murderous beings Hopefully with the nd Cour well be able to see more of the liberation with Rudeus at the chargeThe one sole thing that stuck out to me is the seriously intense levels of visuals and animation not to mention the very subtle details referencing to real life and all of this done by a new studio no less But if you think that this studio are like the recent new ones that just suddenly sprouted out to help tackle the anime industrys problems youre dead wrong Studio Bind a collaboration jointventure from management planning company Egg Firm and White Fox first started helping out in Karakuri Circus before jumping ship into Mushoku Tensei in what has been announced to be a continuous longterm production in a systematic manner And just by hearing the studio White Fox alone you know that youre watching and experiencing something special akin to the likes of ReZero Directed by Gamers director Manabu Okamoto even if his past directorial works arent great the makingup with Mushoku Tensei definitely gave a boost to his career and its great for the most part trying to direct this show and keeping the realism of the series alive to fruitionThe music Im definitely speechless about this one because of all the shows that are stacked in the Best of the Best and Worst Winter  season Mushoku Tensei knows how to differentiate itself from the pack and with a very good reason a starstudded cast of Seiyuus most in particular the comedy god himself Tomozaku Sugita for voicing Rudeuss inner voice with their performances pushing right out of the gate to perfection That is something worth noting for the nd Cour coming upward With such sound and music designs by veterans Jin Aketagawa and Yoshiaki Fujisawa these legends have once again carved their name onto a masterpiece in the making Even better is Yuiko Ooharas songs because like Karakai Jouzu no Takagisan she has once again proved her worth to have a song repertoire of the soothing kind only that this OST is similarly paved in the ways of Spice and Wolf thats just as good as her previous offerings The small tidbit is that her songs here DO actually have a significance to the shows counterparts from songs of Tabibito Traveler to Mezame Awakening for the OP and Only which signifies a love song from Rudeus to the three central girls WOW what symbolismAll in all what a great show despite the controversy for SJWs to lay the elitist treatment I have simply no words for the brillance to wait upon the Isekai that started it all and the long wait it is to finally see Mushoku Tensei get adapted sooner than later even if later than most Isekai to test the waters of the anime spectrumAll ready for the nd Cour        '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_OcVenocEH_"
      },
      "source": [
        "# E - Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMg9ZUvocF6U"
      },
      "source": [
        "우선 sentiment 분류는 어떤 것들은 잘 분류가 되어있지만, 어떤것들은 잘못 분류가 되어 있다. 이는 당연하게 생각 할 수 있겠지만 데이터를 보는 과정에서 몇가지 문제점이 발견되었다. 또한 해당 프로젝트에서 몇가지 한계점 또한 존재한다.\n",
        "- 우선 리뷰를 작성한 유저들은 대체적으로 리뷰를 장문의 에세이 형식으로 쓰는 것을 굉장히 좋아한다.따라서 텍스트의 길이가 위의 결과와 같이 엄청나게 늘어나게 된다. 따라서 인간이 읽어도 긍정인지 부정인지도 판별하기가 굉장히 어렵다. \n",
        "- 손으로 라벨을 붙이는 시간을 줄이기 위해 압도적으로 긍정인 애니메이션 시리즈와 압도적으로 부정인 시리즈를 선정하여 일괄적으로 라벨을 통일하였는데, 이 과정에서 잘못 라벨링이 되어있을 수가 있다. 따라서 학습 또한 잘 못 됐을 가능성이 있다. 이 점을 보완하기 위해서 시간을 가지고 라벨링을 일일히 할 필요가 있어보인다.\n",
        "- 시간을 단축하기 위해 몇가지 3개의 애니메이션 시리즈의 리뷰를 클롤링하였지만, 더 다양한 시리즈의 리뷰들을 크롤링하는 것도 좋을 듯하다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9r9h9aYf2K1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}